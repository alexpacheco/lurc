<!DOCTYPE html>
<html>
<head>
  <title>Introduction to HPC</title>
  <meta charset="utf-8">
  <meta name="description" content="Introduction to HPC">
  <meta name="author" content="https://researchcomputing.lehigh.edu">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  <link rel=stylesheet href="./assets/css/custom.css"></link>
<link rel=stylesheet href="./assets/css/ribbons.css"></link>

  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
        <slide class="title-slide segue nobackground">
  <aside class="gdbar">
    <img src="assets/img/lu.png">
  </aside>
  <hgroup class="auto-fadein">
    <h1>Introduction to HPC</h1>
    <h2>Library &amp; Technology Services</h2>
    <p>https://researchcomputing.lehigh.edu<br/></p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="class" id="slide-1" style="background:#F1E7C8;">
  <hgroup>
    <h2>About Us?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>Who?</p>

<ul>
<li>Unit of Lehigh&#39;s Library &amp; Technology Services within the Center for Innovation in Teaching &amp; Learning</li>
</ul></li>
<li><p>Our Mission</p>

<ul>
<li>We enable Lehigh Faculty, Researchers and Scholars achieve their goals by providing various computational resources; hardware, software, and storage; consulting and training.</li>
</ul></li>
<li><p>Research Computing Staff</p>

<ul>
<li><strong>Alex Pacheco, Manager &amp; XSEDE Campus Champion</strong></li>
<li>Steve Anthony, HPC User Support &amp; System Administrator</li>
<li>Dan Brashler, CAS Senior Computing Consultant</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-2" style="background:#F1E7C8;">
  <hgroup>
    <h2>What do we do?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Hardware Support

<ul>
<li>Provide system administration and support for Lehigh&#39;s HPC clusters.

<ul>
<li>2 University owned and 4 Faculty owned </li>
</ul></li>
<li>Assist with purchase, installation and administration of servers and clusters.</li>
</ul></li>
<li>Data Storage

<ul>
<li>Provide data management services including storing and sharing data. </li>
</ul></li>
<li>Software Support

<ul>
<li>Provide technical support for software applications, install software as requested and assist with purchase of software.</li>
</ul></li>
<li>Training &amp; Consulting

<ul>
<li>Provide education and training programs to facilitate use of HPC resources and general scientific computing needs.</li>
<li>Provide consultation and support for code development and visualization.</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-3" style="background:#F1E7C8;">
  <hgroup>
    <h2>Training &amp; Consulting</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>RC staff guest lecture for various courses and provide various training
seminars in collaboration with other LTS groups</li>
</ul>

<div style='float:left;width:50%;'>
  <ul>
<li>Research Computing at Lehigh (Sep. 7, CSE 411)</li>
<li>Linux: Basic Commands &amp; Environment (Sep. 14, CHM 488, EES 403)</li>
<li>Using SLURM scheduler on Sol (Sep. 21)</li>
<li>Shell Scripting (Sep. 28)</li>
<li>Using Virtualized Software at Lehigh (Oct. 5)</li>
<li>Python Programming (Oct. 12)</li>
<li>RefWorks (Oct. 26)</li>
<li>Document Creation with LaTeX (Nov. 2) </li>
</ul>

</div>
<div style='float:right;width:48%;'>
  <ul>
<li>A Brief Introduction to Linux </li>
<li>Storage Options at Lehigh </li>
<li>Research Data Management</li>
<li>Version Control with GIT</li>
<li>Programming in MATLAB and GNU Octave</li>
<li>Enhancing Research Impact</li>
<li>Programming in R</li>
<li>Parallel Programming Concepts (ME 413, ACCT 398)</li>
<li>Saltstack Config Management (CSE 265)</li>
</ul>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-4" style="background:#F1E7C8;">
  <hgroup>
    <h2>Full Day Workshops</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>During the summer we provide full day workshops on programming topics</li>
<li>Summer 2015 Workshops

<ul>
<li>Modern Fortran Programming</li>
<li>C Programming</li>
</ul></li>
<li>Summer 2017: HPC Parallel Programming Workshop

<ul>
<li>Programming in MPI, OpenMP and OpenACC</li>
</ul></li>
<li>We also host full day workshops broadcast from other Supercomputing Centers

<ul>
<li>XSEDE HPC Monthly Workshop: OpenACC (Dec. 2014)</li>
<li>XSEDE HPC Summer BootCamp: OpenMP, OpenACC, MPI and Hybrid Programming (Jun. 2015, 2016  &amp; 2017)</li>
<li>XSEDE HPC Monthly Workshop: Big Data (Nov. 2015, May 2017 &amp; <strong>Dec. 2017</strong>)

<ul>
<li>To held in EWFM 625 on Dec 5 &amp; 6 from 11AM - 5PM</li>
<li>Registration at the XSEDE portal: <a href="https://portal.xsede.org/course-calendar">https://portal.xsede.org/course-calendar</a></li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Research Computing Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p><strong> Maia </strong></p>

<ul>
<li>32-core Symmetric Multiprocessor (SMP) system available to all Lehigh Faculty, Staff and Students</li>
<li>dual 16-core AMD Opteron 6380 2.5GHz CPU</li>
<li>128GB RAM and 4TB HDD</li>
<li>Theoretical Performance: 640 GFLOPs (640 billion floating point operations per second)</li>
<li>Access: Batch Scheduled, no interactive access to Maia</li>
</ul>

<p>\[
GFLOPs = cores \times clock \times \frac{FLOPs}{cycle}
\]</p>

<p><a href="https://en.wikipedia.org/wiki/FLOPS#FLOPs_per_cycle">FLOPs for various AMD &amp; Intel CPU generation</a></p></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Research Computing Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><strong> Sol </strong>

<ul>
<li>Lehigh&#39;s Flagship High Performance Computing Cluster</li>
<li>9 nodes, dual 10-core Intel Xeon E5-2650 v3 2.3GHz CPU, 25MB Cache, 128GB
RAM, 2x nVIDIA GTX 1080 GPU</li>
<li>33 nodes, dual 12-core Intel Xeon E5-2670 v3 2.3Ghz CPU, 30 MB Cache,
128GB RAM, 2x nVIDIA GTX 1080 GPU</li>
<li>13 nodes, dual 12-core Intel Xeon E5-2650 v4 2.3Ghz CPU, 30 MB Cache, 64GB
RAM</li>
<li>1 node, dual 8-core Intel Xeon 2630 v3 2.4GHz CPU, 20 MB Cache, 512GB RAM</li>
<li>1TB HDD per node</li>
<li>2:1 oversubscribed Infiniband EDR (100Gb/s) interconnect fabric</li>
<li>Theoretical Performance: 47.37 TFLOPs (CPU) + 28.270 TFLOPs (GPU)</li>
<li>Access: Batch Scheduled, interactive on login node for compiling, editing
only</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>LTS Managed Faculty Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><strong>Monocacy</strong>: Ben Felzer, Earth &amp; Environmental Sciences

<ul>
<li>Eight nodes, dual 8-core Intel Xeon E5-2650v2, 2.6GHz, 64GB RAM

<ul>
<li>Theoretical Performance: 2.662TFlops</li>
</ul></li>
</ul></li>
<li><strong>Baltrusaitislab</strong>: Jonas Baltrusaitis, Chemical Engineering

<ul>
<li>Three nodes, dual 16-core AMD Opteron 6376, 2.3Ghz, 128GB RAM

<ul>
<li>Theoretical Performance: 1.766TFlops</li>
</ul></li>
</ul></li>
<li><strong>Pisces</strong>: Keith Moored, Mechanical Engineering and Mechanics

<ul>
<li>Six nodes, dual 10-core Intel Xeon E5-2650v3, 2.3GHz, 64GB RAM, nVIDIA Tesla K80

<ul>
<li>Theoretical Performance: 4.416 TFlops (CPU) + 17.46TFlops (GPU)</li>
</ul></li>
<li>To be merged with Sol in Fall 2017</li>
</ul></li>
<li>Unnamed : decommissioned faculty cluster for prototyping future resources

<ul>
<li>Twenty nodes, dual 8-core Intel Xeon E5-2650v2, 2.6GHz, 64GB RAM

<ul>
<li>Theoretical Performance: 6.656TFlops</li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-8" style="background:#F1E7C8;">
  <hgroup>
    <h2>Total Computational Resources Supported</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">Cluster</th>
<th align="center">Cores</th>
<th align="center">CPU Memory</th>
<th align="center">CPU TFLOPs</th>
<th align="center">GPUs</th>
<th align="center">CUDA Cores</th>
<th align="center">GPU Memory</th>
<th align="center">GPU TFLOPS</th>
</tr>
</thead><tbody>
<tr>
<td align="center">Maia</td>
<td align="center">32</td>
<td align="center">128</td>
<td align="center">0.640</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Monocacy</td>
<td align="center">128</td>
<td align="center">512</td>
<td align="center">2.662</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Unnamed</td>
<td align="center">320</td>
<td align="center">1280</td>
<td align="center">6.656</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Baltrusaitislab</td>
<td align="center">96</td>
<td align="center">384</td>
<td align="center">1.766</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Pisces</td>
<td align="center">120</td>
<td align="center">384</td>
<td align="center">4.416</td>
<td align="center">6</td>
<td align="center">29952</td>
<td align="center">144</td>
<td align="center">17.472</td>
</tr>
<tr>
<td align="center">Sol</td>
<td align="center">1300</td>
<td align="center">6720</td>
<td align="center">47.366</td>
<td align="center">110</td>
<td align="center">281600</td>
<td align="center">880</td>
<td align="center">28.27</td>
</tr>
<tr>
<td align="center">Total</td>
<td align="center">1996</td>
<td align="center">9408</td>
<td align="center">63.507</td>
<td align="center">116</td>
<td align="center">311552</td>
<td align="center">1024</td>
<td align="center">45.742</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Apply for an account</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p><a href="https://idmweb.cc.lehigh.edu/accounts/?page=hpc">Apply for an account at the LTS website</a></p>

<ul>
<li>Click on Services &gt; Account &amp; Password &gt; Lehigh Computing Account &gt; Request an account</li>
<li>Click on the big blue button &quot;Start Special Account Request&quot; &gt; Research Computing Account </li>
<li>Maia

<ul>
<li>Click on &quot;FREE Linux command-line computing&quot;</li>
</ul></li>
<li>Sol: PIs should contact Alex Pacheco or Steve Anthony, web request is not functional

<ul>
<li><del>Click on &quot;Fee-based research computing&quot;</del> </li>
<li>Annual charge of $50/account paid by Lehigh Faculty or Research Staff, and</li>
<li>Annual charge for computing time</li>
</ul></li>
</ul></li>
<li><p>Sharing of accounts is explicitly forbidden</p></li>
<li><p>Users need to be associated with an allocation to run jobs on Sol </p></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Allocation Charges - Effective Oct. 1, 2016</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Cost per core-hour or service unit (SU) is 1&cent;</li>
<li><p>SU is defined as 1 hour of computing on 1 core of the Sol base compute node.</p>

<ul>
<li>One base compute node of Sol consumes 20 SU/hour, 480 SU/day and 175,200 SU/year</li>
</ul></li>
<li><p>PIs can share allocations with their collaborators</p>

<ul>
<li>Minimum Annual Purchase of 50,000 SU - &#36;500/year</li>
<li>Additional Increments of 10,000 SU - &#36;100 per 10K increments</li>
<li>Fixed Allocation cycle: Oct 1 - Sep 30</li>
<li>Unused allocations do not rollover to next allocation cycle</li>
<li>Total available computing time for purchase annually: 1.4M SUs or 1 year of continuous computing on 8 nodes</li>
</ul></li>
<li><p><strong>No &#39;free&#39; computing time provided once allocation has been expended</strong></p></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Condo Investments</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>New sustainable model for High Performance Computing at Lehigh</li>
<li>Faculty (Condo Investor) purchase compute nodes to increase overall capacity of Sol</li>
<li>LTS will provide for the length of hardware warranty, typically 4 years

<ul>
<li>System Administration, Power and Cooling, User Support for Condo
Investments</li>
</ul></li>
<li>Condo Investor

<ul>
<li>receives annual allocation equivalent to their investment</li>
<li>can utilize allocations on all available nodes, including nodes from other
Condo Investors</li>
<li>allows idle cycles on investment to be used by other Sol users</li>
<li>unused allocation will not rollover to the next allocation cycle.</li>
<li>can purchase additional SUs in 10K increments (minimum 50K not required)

<ul>
<li> and must be consumed in current allocation cycle</li>
</ul></li>
</ul></li>
<li>Annual Allocation cycle is Oct. 1 - Sep. 30.</li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-12" style="background:#F1E7C8;">
  <hgroup>
    <h2>Condo Investors</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>Two at initial launch </p>

<ul>
<li>Dimitrios Vavylonis, Physics (1 node)</li>
<li>Wonpil Im, Biological Sciences (25 nodes, 50 GPUs)</li>
<li>Anand Jagota, Chemical Engineering (1 node)</li>
<li>Brian Chen, Computer Science &amp; Engineering (1 node)</li>
<li>Ed Webb &amp; Alp Oztekin, Mechanical Engineering (6 nodes)</li>
<li>Jeetain Mittal &amp; Srinivas Rangarajan, Chemical Engineering (13 nodes, 60 GPUs)</li>
<li>Seth Richards-Shubik, Economics (1 node)</li>
</ul></li>
<li><p>Total SU on Sol after Condo Investments: 11,247,840</p></li>
<li><p>Acquisition in progress</p>

<ul>
<li>Ganesh Balasubramanian, Mechanical Engineering (at least 10 nodes)</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-13" style="background:#F1E7C8;">
  <hgroup>
    <h2>What about Storage resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>LTS provides various storage options.</li>
<li>Some of these are in the cloud and subject to Lehigh&#39;s Cloud Policy</li>
<li>For research, LTS provides a 1PB storage system called Ceph</li>
<li>Ceph is based on the Ceph software</li>
<li>Research groups can purchase a project space on Ceph @ $200/TB/year that can be shared</li>
<li>Ceph is in-house, built, operated and administered by LTS Research Computing Staff.

<ul>
<li>located in Data Center in EWFM with a backup cluster in Packard Lab</li>
</ul></li>
<li>HPC users can write job output directly to their Ceph volume</li>
<li>Ceph volume can be mounted as a network drive on Windows or CIFS on Mac and Linux

<ul>
<li><a href="http://lts.lehigh.edu/services/faq/ceph-faq">See Ceph FAQ</a> for more details</li>
</ul></li>
<li>HPC User home directory quota

<ul>
<li>Maia: 5GB</li>
<li>Sol: 150GB </li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Network Layout Sol &amp; Ceph Storage Cluster</h2>
  </hgroup>
  <article data-timings="">
    <p><img class="fullwidth" src='assets/img/hpcnetwork.png'></p>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Accessing Research Computing Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Sol &amp; Faculty Clusters: accessible using ssh while on Lehigh&#39;s network

<ul>
<li><code>ssh username@sol.cc.lehigh.edu</code></li>
</ul></li>
<li>Maia: No direct access to Maia, instead login to Polaris

<ul>
<li><code>ssh username@polaris.cc.lehigh.edu</code></li>
<li>Polaris is a gateway that also hosts the batch scheduler for Maia</li>
<li>No computing software including compilers is available on Polaris</li>
<li>Login to Polaris and request computing time on Maia including interactive access

<ul>
<li>On Polaris, run the <code>maiashell</code> command to get interactive access to
Maia for 15 minutes.</li>
</ul></li>
</ul></li>
<li>If you are not on Lehigh&#39;s network, login to the ssh gateway to get to Research Computing resources

<ul>
<li><code>ssh username@ssh.cc.lehigh.edu</code></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Available Software</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Commercial, Free and Open source software is installed on

<ul>
<li><a href="https://webapps.lehigh.edu/dokuwiki/sites/researchcomputing/doku.php?id=maia#installed_software">Maia</a>: /zhome/Apps</li>
<li><a href="https://webapps.lehigh.edu/dokuwiki/sites/researchcomputing/doku.php?id=sol#installed_software">Sol</a>: /share/Apps</li>
</ul></li>
<li>Software is managed using module environment

<ul>
<li>Why? We may have different versions of same software or software built with different compilers</li>
<li>Module environment allows you to dynamically change your *nix environment based on software being used</li>
<li>Standard on many University and national High Performance Computing resource since circa 2011</li>
</ul></li>
<li>How to use Sol/Maia Software on your <a href="https://webapps.lehigh.edu/dokuwiki/sites/researchcomputing/doku.php?id=linux">linux</a> workstation</li>
<li>LTS provides <a href="https://software.lehigh.edu">licensed and open source software</a> for Windows, Mac and Linux and <a href="https://gogs.cc.lehigh.eu">Gogs</a>, a self hosted Git Service or Github clone </li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-17" style="background:#F1E7C8;">
  <hgroup>
    <h2>Installed Software</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:45%;'>
  <ul>
<li>Chemistry/Materials Science

<ul>
<li>CPMD</li>
<li>GAMESS</li>
<li>Gaussian</li>
<li>NWCHEM</li>
<li>Quantum Espresso</li>
<li><em>VASP</em></li>
</ul></li>
<li>Molecular Dynamics

<ul>
<li>Desmond</li>
<li>GROMACS</li>
<li>LAMMPS</li>
<li>NAMD</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:45%;'>
  <ul>
<li>Computational Fluid Dynamics

<ul>
<li>Abaqus</li>
<li>Ansys</li>
<li>Comsol</li>
<li>OpenFOAM</li>
<li>OpenSees</li>
</ul></li>
<li>Math

<ul>
<li>GNU Octave</li>
<li>Magma</li>
<li>Maple</li>
<li>Mathematica</li>
<li>Matlab</li>
</ul></li>
</ul>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-18" style="background:#F1E7C8;">
  <hgroup>
    <h2>More Software</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:35%;'>
  <ul>
<li>Scripting Languages

<ul>
<li>R</li>
<li>Perl</li>
<li>Python</li>
</ul></li>
<li>Compilers

<ul>
<li>GNU</li>
<li>Intel</li>
<li>PGI</li>
<li>CUDA</li>
</ul></li>
<li>Parallel Programming

<ul>
<li>MVAPICH2</li>
<li>OpenMPI</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:65%;'>
  <ul>
<li>Libraries

<ul>
<li>BLAS/LAPACK/GSL/SCALAPACK</li>
<li>Boost</li>
<li>FFTW</li>
<li>Intel MKL</li>
<li>HDF5</li>
<li>NetCDF</li>
<li>METIS/PARMETIS</li>
<li>PetSc</li>
<li>QHull/QRupdate</li>
<li>SuiteSparse</li>
<li>SuperLU</li>
</ul></li>
</ul>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-19" style="background:#F1E7C8;">
  <hgroup>
    <h2>More Software</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:30%;'>
  <ul>
<li>Visualization Tools

<ul>
<li>Avogadro </li>
<li>GaussView</li>
<li>GNUPlot</li>
<li>PWGui</li>
<li>PyMol</li>
<li>VMD</li>
<li>XCrySDen</li>
</ul></li>
<li>Other Tools

<ul>
<li>CMake</li>
<li>Lmod</li>
<li>Scons</li>
<li>SPACK</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:70%;'>
  
</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Module Command</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">Command</th>
<th align="center">Description</th>
</tr>
</thead><tbody>
<tr>
<td align="center"><code>module avail</code></td>
<td align="center">show list of software available on resource</td>
</tr>
<tr>
<td align="center"><code>module load abc</code></td>
<td align="center">add software <code>abc</code> to your environment (modify your <code>PATH</code>, <code>LD_LIBRARY_PATH</code> etc as needed)</td>
</tr>
<tr>
<td align="center"><code>module unload abc</code></td>
<td align="center">remove <code>abc</code> from your environment</td>
</tr>
<tr>
<td align="center"><code>module swap abc1 abc2</code></td>
<td align="center">swap <code>abc1</code> with <code>abc2</code> in your environment</td>
</tr>
<tr>
<td align="center"><code>module purge</code></td>
<td align="center">remove all modules from your environment</td>
</tr>
<tr>
<td align="center"><code>module show abc</code></td>
<td align="center">display what variables are added or modified in your environment</td>
</tr>
<tr>
<td align="center"><code>module help abc</code></td>
<td align="center">display help message for the module <code>abc</code></td>
</tr>
</tbody></table>

<ul>
<li>Users who prefer not to use the module environment will need to modify their
.bashrc or .tcshrc files. Run <code>module show</code> for list variables that need
modified, appended or prepended</li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Creating your own modules</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>You can always install a software in your home directory</li>
<li>Stay compliant with software licensing</li>
<li>Modify your .bashrc/.tcshrc to add software to your path, OR</li>
<li>create a module and dynamically load it so that it doesn&#39;t interfere 
with other software installed on the system

<ul>
<li>e.g. You might want a different version of openmpi installed </li>
<li>the system admin may not want install it system wide for just one user</li>
</ul></li>
<li>Add the directory where you will install the module files to the variable 
MODULEPATH in .bashrc/.tcshrc</li>
</ul>

<pre><code class="sh"># My .bashrc file
export MODULEPATH=${MODULEPATH}:/home/alp514/modulefiles
</code></pre>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-22" style="background:#F1E7C8;">
  <hgroup>
    <h2>Module File Example</h2>
  </hgroup>
  <article data-timings="">
    <p><img width = '900px' src = 'assets/img/mcr.png'></p>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-23" style="background:#F1E7C8;">
  <hgroup>
    <h2>Compilers</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Various versions of compilers installed on Sol </li>
<li>Open Source: GNU Compiler (also called gcc even though gcc is the c compiler)

<ul>
<li>4.8.5 (system default), 5.3.0, 6.1.0 and 7.1.0</li>
</ul></li>
<li>Commercial: Only two seats of each

<ul>
<li>Intel Compiler: 16.0.3, 17.0.0 and 17.0.3</li>
<li>Portland Group or PGI: 16.5, 16.10, 17.4 and 17.7</li>
</ul></li>
<li><em>We are licensed to install any available version</em></li>
<li>On Sol, all except gcc 4.8.5 are available via the module environment</li>
</ul>

<table><thead>
<tr>
<th align="center">Language</th>
<th align="center">GNU</th>
<th align="center">Intel</th>
<th align="center">PGI</th>
</tr>
</thead><tbody>
<tr>
<td align="center">Fortran</td>
<td align="center">gfortran</td>
<td align="center">ifort</td>
<td align="center">pgf77/pgf90</td>
</tr>
<tr>
<td align="center">C</td>
<td align="center">gcc</td>
<td align="center">icc</td>
<td align="center">pgcc</td>
</tr>
<tr>
<td align="center">C++</td>
<td align="center">g++</td>
<td align="center">icpc</td>
<td align="center">pgCC</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-24" style="background:#F1E7C8;">
  <hgroup>
    <h2>Compiling Code</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Usage: <code>&lt;compiler&gt; &lt;options&gt; &lt;source code&gt;</code></li>
<li>Example:

<ul>
<li><code>ifort -o saxpyf saxpy.f90</code></li>
<li><code>gcc -o saxpyc saxpy.c</code></li>
</ul></li>
<li>Common Compiler options or flags

<ul>
<li><code>-o myexec</code>: compile code and create an executable myexec. If this option is not given, then a default <code>a.out</code> is created.</li>
<li><code>-l{libname}</code>: link compiled code to a library called libname. e.g. to use lapack libraries, add <code>-llapack</code> as a compiler flag.</li>
<li><code>-L{directory path}</code>: directory to search for libraries. e.g. <code>-L/usr/lib64 -llapack</code> will search for lapack libraries in /usr/lib64.</li>
<li><code>-I{directory path}</code>: directory to search for include files and fortran modules.</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-25" style="background:#F1E7C8;">
  <hgroup>
    <h2>Compilers for Parallel Programming: OpenMP &amp; TBB</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>OpenMP support is built-in</li>
</ul>

<table><thead>
<tr>
<th align="center">Compiler</th>
<th align="center">OpenMP Flag</th>
</tr>
</thead><tbody>
<tr>
<td align="center">GNU</td>
<td align="center">-fopenmp</td>
</tr>
<tr>
<td align="center">Intel</td>
<td align="center">-qopenmp</td>
</tr>
<tr>
<td align="center">PGI</td>
<td align="center">-openmp</td>
</tr>
</tbody></table>

<ul>
<li>TBB is available as part of Intel Compiler suite

<ul>
<li><code>-L$TBBROOT/lib/intel64_lin/gcc4.4 -ltbb</code> where <code>$TBBROOT</code> depends on the Intel Compiler Suite you want to use.

<ul>
<li>use <code>module show intel/&lt;version&gt;</code> to get value of <code>$TBBROOT</code></li>
<li>Not sure if this will work for PGI Compilers</li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-26" style="background:#F1E7C8;">
  <hgroup>
    <h2>Compilers for Parallel Programming: MPI</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>MPI is a library and not a compiler, built or compiled for different compilers.</li>
</ul>

<table><thead>
<tr>
<th align="center">Language</th>
<th align="center">Compile Command</th>
</tr>
</thead><tbody>
<tr>
<td align="center">Fortran</td>
<td align="center">mpif90</td>
</tr>
<tr>
<td align="center">C</td>
<td align="center">mpicc</td>
</tr>
<tr>
<td align="center">C++</td>
<td align="center">mpicxx</td>
</tr>
</tbody></table>

<ul>
<li>The MPI compiler command is just a wrapper around the underlying compiler</li>
</ul>

<pre><code class="bash">[alp514.sol](1080): mpif90 -show
ifort -fPIC -I/share/Apps/mvapich2/2.1/intel-16.0.3/include -I/share/Apps/mvapich2/2.1/intel-16.0.3/include 
  -L/share/Apps/mvapich2/2.1/intel-16.0.3/lib -lmpifort -Wl,-rpath -Wl,/share/Apps/mvapich2/2.1/intel-16.0.3/lib 
  -Wl,--enable-new-dtags -lmpi
</code></pre>

<ul>
<li>Usage: <code>&lt;compiler&gt; &lt;options&gt; &lt;source code&gt;</code></li>
<li>Example:

<ul>
<li><code>mpif90 -o laplace_f90 laplace_mpi.f90</code></li>
<li><code>mpicc -o laplace_c laplace_mpi.c</code></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-27" style="background:#F1E7C8;">
  <hgroup>
    <h2>MPI Libraries</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>There are two different MPI implementations commonly used</li>
<li><code>MPICH</code>: Developed by Argonned National Laboratory

<ul>
<li>used as a starting point for various commercial and open source MPI libraries</li>
<li><code>MVAPICH2</code>: Developed by D. K. Panda with support for  InfiniBand, iWARP, RoCE, and Intel Omni-Path. (default MPI on Sol)</li>
<li><code>Intel MPI</code>: Intel&#39;s version of MPI. <strong>You need this for Xeon Phi MICs</strong>.

<ul>
<li>available in cluster edition of Intel Compiler Suite. Not available at Lehigh</li>
</ul></li>
<li><code>IBM MPI</code> for IBM BlueGene and <code>CRAY MPI</code> for Cray systems</li>
</ul></li>
<li><code>OpenMPI</code>: A Free, Open Source implementation from merger of three well know MPI implementations. Can be used for commodity network as well as high speed network

<ul>
<li><code>FT-MPI</code> from the University of Tennessee</li>
<li><code>LA-MPI</code> from Los Alamos National Laboratory</li>
<li><code>LAM/MPI</code> from Indiana University</li>
</ul></li>
</ul>

<p>--- ,class</p>

<h2>Running MPI Programs</h2>

<ul>
<li>Every MPI implementation come with their own job launcher: <code>mpiexec</code>, <code>mpirun</code> (OpenMPI)  or <code>mpirun_rsh</code> (MVAPICH2)</li>
<li>Example:

<ul>
<li><code>mpiexec [options] &lt;program name&gt; [program options]</code></li>
</ul></li>
<li>Required options: number of processes and list of hosts on which to run program </li>
</ul>

<table><thead>
<tr>
<th align="center">Option Description</th>
<th align="center">mpiexec</th>
<th align="center">mpirun</th>
<th align="center">mpirun_rsh</th>
</tr>
</thead><tbody>
<tr>
<td align="center">run on <code>x</code> cores</td>
<td align="center">-n x</td>
<td align="center">-n x</td>
<td align="center">-n x</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">-np x</td>
<td align="center">-np x</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">location of the hostfile</td>
<td align="center">-f filename</td>
<td align="center">-machinefile filename</td>
<td align="center">-hostfile filename</td>
</tr>
<tr>
<td align="center">list of hosts</td>
<td align="center">--host <host1,host2,...,hostN></td>
<td align="center">--host <host1,host2,...,hostN></td>
<td align="center"></td>
</tr>
</tbody></table>

<ul>
<li>To run a MPI code, you need to use the launcher from the same implementation that was used to compile the code.</li>
<li>For e.g.: You cannot compile code with OpenMPI and run using the MPICH and MVAPICH2&#39;s launcher

<ul>
<li>Since MVAPICH2 is based on MPICH, you can launch MVAPICH2 compiled code using MPICH&#39;s launcher.</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-28" style="background:#F1E7C8;">
  <hgroup>
    <h2>Compiling Using Makefiles</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Makefile is a file containing a set of directives used with the make build automation tool.

<ul>
<li>directs make on how to compile and link a program.</li>
</ul></li>
<li>Using C/C++ as an example, when a C/C++ source file is changed, it must be recompiled. </li>
<li>If a header file has changed, each C/C++ source file that includes the header file must be recompiled to be safe. </li>
<li>Each compilation produces an object file corresponding to the source file. </li>
<li>Finally, if any source file has been recompiled, all the object files, whether newly made or saved from previous compilations, must be linked together to produce the new executable program.</li>
<li>These instructions with their dependencies are specified in a makefile. </li>
<li>If none of the files that are prerequisites have been changed since the last time the program was compiled, no actions take place. </li>
<li>For large software projects, using Makefiles can substantially reduce build times if only a few source files have changed.</li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-29" style="background:#F1E7C8;">
  <hgroup>
    <h2>Makefile Examples</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:;'>
  <pre><code class="bash">ifeq ($(COMP),gnu)
        CC = gcc
        FC = gfortran
        CFLAGS = -cpp
        OFLAGS = -fopenmp
        BINF = pif pif_omp pif_ompr
        BINC = pic pic_omp pic_ompr
else ifeq ($(COMP),intel)
        CC = icc
        FC = ifort
        CFLAGS = -fpp
        OFLAGS = -qopenmp
        BINF = pif pif_omp pif_ompr
        BINC = pic pic_omp pic_ompr
else
        CC = pgcc
        FC = pgf90
        CFLAGS = -Mpreprocess
        OFLAGS = -mp
        AFLAGS = -acc -Minfo=accel -ta=tesla:cc60 -Mcuda=kepler+
        BINF = pif pif_omp pif_ompr pif_acc
        BINC = pic pic_omp pic_ompr pic_acc
endif

ifeq ($(precision),single)
        PREC = -Mpreprocess
else
        PREC = -DDP -Mpreprocess
endif

</code></pre>

</div>
<div style='float:right;width:;'>
  <pre><code class="bash">all: $(BINC) $(BINF)
pic:
        $(CC) $(CFLAGS) $(PREC) -o pic pi_serial.c
pif:
        $(FC) $(CFLAGS) $(PREC) -o pif pi_serial.f90
pic_ompr:
        $(CC) $(CFLAGS) $(PREC) $(OFLAGS) -o pic_ompr pi_ompr.c
pic_omp:
        $(CC) $(CFLAGS) $(PREC) $(OFLAGS) -o pic_omp pi_omp.c
pif_ompr:
        $(FC) $(CFLAGS) $(PREC) $(OFLAGS) -o pif_ompr pi_ompr.f90
pif_omp:
        $(FC) $(CFLAGS) $(PREC) $(OFLAGS) -o pif_omp pi_omp.f90
pic_acc:
        $(CC) $(CFLAGS) $(PREC) $(AFLAGS) -o pic_acc pi_acc.c
pif_acc:
        $(FC) $(CFLAGS) $(PREC) $(AFLAGS) -o pif_acc pi_acc.f90
clean:
        rm -rf $(BINC) $(BINF) *~

</code></pre>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-30" style="background:#F1E7C8;">
  <hgroup>
    <h2>Cluster Environment</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>A cluster is a group of computers (nodes) that works together closely</li>
</ul>

<div style='float:left;width:30%;'>
  <ul>
<li><p>Two types of nodes</p>

<ul>
<li>Head/Login Node</li>
<li>Compute Node</li>
</ul></li>
<li><p>Multi-user environment</p></li>
<li><p>Each user may have multiple jobs running simultaneously</p></li>
</ul>

</div>
<div style='float:right;width:65%;'>
  <p><img width = '640px' src = 'assets/img/solnetwork.png'></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>How to run jobs</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>All compute intensive jobs are scheduled</li>
<li>Write a script to submit jobs to a scheduler

<ul>
<li>need to have some background in shell scripting (bash/tcsh)</li>
</ul></li>
<li>Need to specify

<ul>
<li>Resources required (which depends on configuration)

<ul>
<li>number of nodes</li>
<li>number of processes per node</li>
<li>memory per node</li>
</ul></li>
<li>How long do you want the resources

<ul>
<li>have an estimate for how long your job will run</li>
</ul></li>
<li>Which queue to submit jobs

<ul>
<li>SLURM uses the term <em>partition</em> instead of <em>queue</em></li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Scheduler &amp; Resource Management</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>A software that manages resources (CPU time, memory, etc) and schedules job execution</p>

<ul>
<li>Sol: Simple Linux Utility for Resource Management (SLURM)</li>
<li>Others:  Portable Batch System (PBS)

<ul>
<li>Scheduler: Maui</li>
<li>Resource Manager: Torque</li>
<li>Allocation Manager: Gold</li>
</ul></li>
</ul></li>
<li><p>A job can be considered as a user’s request to use a certain amount of resources for a certain amount of time</p></li>
<li><p>The Scheduler or queuing system determines</p>

<ul>
<li>The order jobs are executed</li>
<li>On which node(s) jobs are executed</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Job Scheduling</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:50%;'>
  <ul>
<li><p>Map jobs onto the node-time space</p>

<ul>
<li>Assuming CPU time is the only resource</li>
</ul></li>
<li><p>Need to find a balance between</p>

<ul>
<li>Honoring the order in which jobs are received</li>
<li>Maximizing resource utilization</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:45%;'>
  <p><img width = '440px' src = 'assets/img/JobSchedule-1.png'></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Backfilling</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:50%;'>
  <ul>
<li>A strategy to improve utilization

<ul>
<li>Allow a job to jump ahead of others when there are enough idle nodes</li>
<li>Must not affect the estimated start time of the job with the highest priority</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:45%;'>
  <p><img width = '440px' src = 'assets/img/JobSchedule-2.png'></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>How much time must I request</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Ask for an amount of time that is

<ul>
<li>Long enough for your job to complete</li>
<li>As short as possible to increase the chance of backfilling</li>
</ul></li>
</ul>

<div style='float:left;width:45%;'>
  <p><img width = '360px' src = 'assets/img/JobSchedule-3.png'></p>

</div>
<div style='float:right;width:45%;'>
  <p><img width = '360px' src = 'assets/img/JobSchedule-4.png'></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class small" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Available Queues</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">Cluster</th>
<th align="center">Partition Name</th>
<th align="center">Max Runtime in hours</th>
<th align="center">Max SU consumed node per hour</th>
</tr>
</thead><tbody>
<tr>
<td align="center">Sol</td>
<td align="center"><em>lts</em></td>
<td align="center">72</td>
<td align="center">20 (will change to 18+2)</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">imlab</td>
<td align="center">48</td>
<td align="center">22</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">imlab-gpu</td>
<td align="center">48</td>
<td align="center">24</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"><em>eng</em></td>
<td align="center">72</td>
<td align="center">24 (will change to 22+2)</td>
</tr>
<tr>
<td align="center"></td>
<td align="center"><em>engc</em></td>
<td align="center">72</td>
<td align="center">24 (will change to 22+2)</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">all-cpu</td>
<td align="center">48</td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center">all-gpu</td>
<td align="center">48</td>
<td align="center"></td>
</tr>
</tbody></table>

<ul>
<li>Maia</li>
</ul>

<table><thead>
<tr>
<th align="center">Queue Name</th>
<th align="center">Max Runtime in hours</th>
<th align="center">Max Simultaneous Core-hours</th>
</tr>
</thead><tbody>
<tr>
<td align="center">smp-test</td>
<td align="center">1</td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">smp</td>
<td align="center">96</td>
<td align="center">384</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>How much memory can or should I use per core?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>The amount of installed memory less the amount that is used by the operating system and other utilities</p></li>
<li><p>A general rule of thumb on most HPC resources: leave 1-2GB for the OS to run. </p></li>
</ul>

<table><thead>
<tr>
<th align="center">Cluster</th>
<th align="center">Partition</th>
<th align="center">Max Memory/core (GB)</th>
<th align="center">Recommended Memory/Core (GB)</th>
</tr>
</thead><tbody>
<tr>
<td align="center">Sol</td>
<td align="center">lts</td>
<td align="center">6.4</td>
<td align="center">6.2</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">eng/imlab/imlab-gpu</td>
<td align="center">5.3</td>
<td align="center">5.1</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">engc</td>
<td align="center">2.66</td>
<td align="center">2.4</td>
</tr>
</tbody></table>

<ul>
<li><p><span class="alert">if you need to run a single core job that requires 10GB memory in the imlab partition, you need to request 2 cores even though you are only using
     1 core.</span>  </p></li>
<li><p>Maia: Users need to specify memory required in their submit script. Max
memory that should be requested is 126GB.</p></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class small" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Useful SBATCH Directives</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">SLURM Directive</th>
<th align="center">Description</th>
</tr>
</thead><tbody>
<tr>
<td align="center">#SBATCH --partition=queuename</td>
<td align="center">Submit job to the <em>queuename</em> partition.</td>
</tr>
<tr>
<td align="center">#SBATCH --time=hh:mm:ss</td>
<td align="center">Request resources to run job for <em>hh</em> hours, <em>mm</em> minutes and <em>ss</em> seconds.</td>
</tr>
<tr>
<td align="center">#SBATCH --nodes=m</td>
<td align="center">Request resources to run job on <em>m</em> nodes.</td>
</tr>
<tr>
<td align="center">#SBATCH --ntasks-per-node=n</td>
<td align="center">Request resources to run job on <em>n</em> processors on each node requested.</td>
</tr>
<tr>
<td align="center">#SBATCH --ntasks=n</td>
<td align="center">Request resources to run job on a total of <em>n</em> processors.</td>
</tr>
<tr>
<td align="center">#SBATCH --job-name=jobname</td>
<td align="center">Provide a name, <em>jobname</em> to your job.</td>
</tr>
<tr>
<td align="center">#SBATCH --output=filename.out</td>
<td align="center">Write SLURM standard output to file filename.out.</td>
</tr>
<tr>
<td align="center">#SBATCH --error=filename.err</td>
<td align="center">Write SLURM standard error to file filename.err.</td>
</tr>
<tr>
<td align="center">#SBATCH --mail-type=events</td>
<td align="center">Send an email after job status events is reached.</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">events can be NONE, BEGIN, END, FAIL, REQUEUE, ALL, TIME_LIMIT(_90,80)</td>
</tr>
<tr>
<td align="center">#SBATCH --mail-user=address</td>
<td align="center">Address to send email.</td>
</tr>
<tr>
<td align="center">#SBATCH --account=mypi</td>
<td align="center">charge job to the <strong>mypi</strong> account</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class small" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Useful SBATCH Directives (contd)</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">SLURM Directive</th>
<th align="center">Description</th>
</tr>
</thead><tbody>
<tr>
<td align="center">#SBATCH --qos=nogpu</td>
<td align="center">Request a quality of service (qos)  for the job in <code>imlab</code>, <code>engc</code> partitions.</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">Job will remain in queue indefinitely if you do not specify qos</td>
</tr>
<tr>
<td align="center">#SBATCH --gres=gpu:#</td>
<td align="center">Specifies number of gpus requested in the gpu partitions</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">You can request 1 or 2 gpus with a minimum of 1 core or cpu per gpu</td>
</tr>
</tbody></table>

<ul>
<li>SLURM can also take short hand notation for the directives</li>
</ul>

<table><thead>
<tr>
<th align="center">Long Form</th>
<th align="center">Short Form</th>
</tr>
</thead><tbody>
<tr>
<td align="center">--partition=queuename</td>
<td align="center">-p queuename</td>
</tr>
<tr>
<td align="center">--time=hh:mm:ss</td>
<td align="center">-t hh:mm:ss</td>
</tr>
<tr>
<td align="center">--nodes=m</td>
<td align="center">-N m</td>
</tr>
<tr>
<td align="center">--ntasks=n</td>
<td align="center">-n n</td>
</tr>
<tr>
<td align="center">--account=mypi</td>
<td align="center">-A mypi</td>
</tr>
<tr>
<td align="center">--job-name=jobname</td>
<td align="center">-J jobname</td>
</tr>
<tr>
<td align="center">--output=filename.out</td>
<td align="center">-o filename.out</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>SBATCH Filename Patterns</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>sbatch allows for a filename pattern to contain one or more replacement
symbols, which are a percent sign &quot;%&quot; followed by a letter (e.g. %j). </li>
</ul>

<table><thead>
<tr>
<th align="center">Pattern</th>
<th align="center">Description</th>
</tr>
</thead><tbody>
<tr>
<td align="center">%A</td>
<td align="center">Job array&#39;s master job allocation number.</td>
</tr>
<tr>
<td align="center">%a</td>
<td align="center">Job array ID (index) number.</td>
</tr>
<tr>
<td align="center">%J</td>
<td align="center">jobid.stepid of the running job. (e.g. &quot;128.0&quot;)</td>
</tr>
<tr>
<td align="center">%j</td>
<td align="center">jobid of the running job.</td>
</tr>
<tr>
<td align="center">%N</td>
<td align="center">short hostname. This will create a separate IO file per node.</td>
</tr>
<tr>
<td align="center">%n</td>
<td align="center">Node identifier relative to current job (e.g. &quot;0&quot; is the first node of the running job) This will create a separate IO file per node.</td>
</tr>
<tr>
<td align="center">%s</td>
<td align="center">stepid of the running job.</td>
</tr>
<tr>
<td align="center">%t</td>
<td align="center">task identifier (rank) relative to current job. This will create a separate IO file per task.</td>
</tr>
<tr>
<td align="center">%u</td>
<td align="center">User name.</td>
</tr>
<tr>
<td align="center">%x</td>
<td align="center">Job name.</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class small" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Useful PBS Directives</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">PBS Directive</th>
<th align="left">Description</th>
</tr>
</thead><tbody>
<tr>
<td align="center">#PBS -q queuename</td>
<td align="left">Submit job to the <em>queuename</em> queue.</td>
</tr>
<tr>
<td align="center">#PBS -l walltime=hh:mm:ss</td>
<td align="left">Request resources to run job for <em>hh</em> hours, <em>mm</em> minutes and <em>ss</em> seconds.</td>
</tr>
<tr>
<td align="center">#PBS -l nodes=m:ppn=n</td>
<td align="left">Request resources to run job on <em>n</em> processors each on <em>m</em> nodes.</td>
</tr>
<tr>
<td align="center">#PBS -l mem=xGB</td>
<td align="left">Request <em>xGB</em> per node requested, applicable on Maia only</td>
</tr>
<tr>
<td align="center">#PBS -N jobname</td>
<td align="left">Provide a name, <em>jobname</em> to your job.</td>
</tr>
<tr>
<td align="center">#PBS -o filename.out</td>
<td align="left">Write PBS standard output to file filename.out.</td>
</tr>
<tr>
<td align="center">#PBS -e filename.err</td>
<td align="left">Write PBS standard error to file filename.err.</td>
</tr>
<tr>
<td align="center">#PBS -j oe</td>
<td align="left">Combine PBS standard output and error to the same file.</td>
</tr>
<tr>
<td align="center">#PBS -M your email address</td>
<td align="left">Address to send email.</td>
</tr>
<tr>
<td align="center">#PBS -m status</td>
<td align="left">Send an email after job status status is reached.</td>
</tr>
<tr>
<td align="center"></td>
<td align="left">status can be a (abort), b (begin) or e (end). The arguments can be combined</td>
</tr>
<tr>
<td align="center"></td>
<td align="left">for e.g. abe will send email when job begins and either aborts or ends</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class pbs" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Useful PBS/SLURM environmental variables</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">SLURM Command</th>
<th align="center">Description</th>
<th align="center">PBS Command</th>
</tr>
</thead><tbody>
<tr>
<td align="center">SLURM_SUBMIT_DIR</td>
<td align="center">Directory where the <code>qsub</code> command was executed</td>
<td align="center">PBS_O_WORKDIR</td>
</tr>
<tr>
<td align="center">SLURM_JOB_NODELIST</td>
<td align="center">Name of the file that contains a list of the HOSTS provided for the job</td>
<td align="center">PBS_NODEFILE</td>
</tr>
<tr>
<td align="center">SLURM_NTASKS</td>
<td align="center">Total number of cores for job</td>
<td align="center">PBS_NP</td>
</tr>
<tr>
<td align="center">SLURM_JOBID</td>
<td align="center">Job ID number given to this job</td>
<td align="center">PBS_JOBID</td>
</tr>
<tr>
<td align="center">SLURM_JOB_PARTITION</td>
<td align="center">Queue job is running in</td>
<td align="center">PBS_QUEUE</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">Walltime in secs requested</td>
<td align="center">PBS_WALLTIME</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">Name of the job. This can be set using the -N option in the PBS script</td>
<td align="center">PBS_JOBNAME</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">Indicates job type, PBS_BATCH or PBS_INTERACTIVE</td>
<td align="center">PBS_ENVIRONMENT</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">value of the SHELL variable in the environment in which qsub was executed</td>
<td align="center">PBS_O_SHELL</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">Home directory of the user running qsub</td>
<td align="center">PBS_O_HOME</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Basic Job Manager Commands</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Submission</li>
<li>Monitoring</li>
<li>Manipulating</li>
<li>Reporting</li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-44" style="background:#F1E7C8;">
  <hgroup>
    <h2>Job Types</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Interactive Jobs

<ul>
<li>Set up an interactive environment on compute nodes for users</li>
<li>Will log you into a compute node and wait for your prompt</li>
<li>Purpose: testing and debugging code. <strong>Do not run jobs on head node!!!</strong>

<ul>
<li>All compute node have a naming convention <strong>sol-[a,b,c]###</strong></li>
<li>head node is <strong>sol</strong></li>
</ul></li>
</ul></li>
<li>Batch Jobs

<ul>
<li>Executed using a batch script without user intervention

<ul>
<li>Advantage: system takes care of running the job</li>
<li>Disadvantage: cannot change sequence of commands after submission</li>
</ul></li>
<li>Useful for Production runs</li>
<li>Workflow: write a script -&gt; submit script -&gt; take mini vacation -&gt;
analyze results</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Job Types: Interactive</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>PBS: Use <code>qsub -I</code> command with PBS Directives</p>

<ul>
<li>   <code>qsub -I -V -l walltime=&lt;hh:mm:ss&gt;,nodes=&lt;# of nodes&gt;:ppn=&lt;# of core/node&gt; -q &lt;queue
name&gt;</code></li>
</ul></li>
<li><p>SLURM:  Use <code>srun</code> command with SBATCH Directives followed by <code>--pty /bin/bash</code></p>

<ul>
<li><code>srun --time=&lt;hh:mm:ss&gt; --nodes=&lt;# of nodes&gt; --ntasks-per-node=&lt;#
of core/node&gt; -p &lt;queue name&gt; --pty /bin/bash</code></li>
<li>If you have <code>soltools</code> module loaded, then use <code>interact</code> with at
least one SBATCH Directive

<ul>
<li><code>interact -t 20</code> [Assumes <code>-p lts -n 1 -N 20</code>]</li>
</ul></li>
</ul></li>
<li><p>Run a job interactively replace <code>--pty /bin/bash --login</code> with the
 appropriate command. </p>

<ul>
<li>For e.g. <code>srun -t 20 -n 1 -p imlab --qos=nogpu $(which lammps) -in in.lj
-var x 1 -var n 1</code></li>
<li>Default values are 3 days, 1 node, 20 tasks per node and lts
partition</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Job Types: Batch</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Workflow: write a script -&gt; submit script -&gt; take mini vacation -&gt; analyze
results</li>
<li><p>Submitting Batch Jobs</p>

<ul>
<li>PBS: <code>qsub filename</code></li>
<li>SLURM: <code>sbatch filename</code></li>
</ul></li>
<li><p><code>qsub</code> and <code>sbatch</code> can take the options for <code>#PBS</code> and <code>#SBATCH</code> as command line arguments</p>

<ul>
<li><code>qsub -l walltime=1:00:00,nodes=1:ppn=16 -q normal filename</code></li>
<li><code>sbatch --time=1:00:00 --nodes=1 --ntasks-per-node=20 -p lts filename</code> </li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class big" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Minimal submit script for Serial Jobs</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="bash">#!/bin/bash
#PBS -q smp
#PBS -l walltime=1:00:00
#PBS -l nodes=1:ppn=1
#PBS -l mem=4GB
#PBS -N myjob

cd ${PBS_O_WORKDIR}
./myjob &lt; filename.in &gt; filename.out

</code></pre>

<pre><code class="bash">#!/bin/bash
#SBATCH --partition=lts
#SBATCH --time=1:00:00
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --job-name myjob

cd ${SLURM_SUBMIT_DIR}
./myjob &lt; filename.in &gt; filename.out

</code></pre>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class big" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Minimal submit script for MPI Job</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:50%;'>
  <pre><code class="bash">#!/bin/bash
#SBATCH --partition=lts
#SBATCH --time=1:00:00
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=20
## For --partition=imlab, 
###  use --ntasks-per-node=22
### and --qos=nogpu
#SBATCH --job-name myjob

module load mvapich2

cd ${SLURM_SUBMIT_DIR}
srun ./myjob &lt; filename.in &gt; filename.out

exit
</code></pre>

</div>
<div style='float:right;width:48%;'>
  <pre><code class="bash">#!/bin/bash
#PBS -q normal
#PBS -l walltime=1:00:00
#PBS -l nodes=2:ppn=16
#PBS -N myjob

module load openmpi/1.6.5/pgi/13.10

cd ${PBS_O_WORKDIR}

mpiexec -n $PBS_PPN -f $PBS_NODEFILE ./myjob \
   &lt; filename.in &gt; filename.out

exit
</code></pre>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class big" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Minimal submit script for OpenMP Job</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:50%;'>
  <pre><code class="bash">#!/bin/tcsh
#SBATCH --partition=imlab
# Directives can be combined on one line
#SBATCH --time=1:00:00 --nodes=1 --ntasks-per-node=22
#SBATCH --qos=nogpu
#SBATCH --job-name myjob

cd ${SLURM_SUBMIT_DIR}
# Use either
setenv OMP_NUM_THREADS 22
./myjob &lt; filename.in &gt; filename.out

# OR
OMP_NUM_THREADS=22 ./myjob &lt; filename.in &gt; filename.out

exit
</code></pre>

</div>
<div style='float:right;width:48%;'>
  <pre><code class="bash">#!/bin/bash
#PBS -q normal
#PBS -l walltime=1:00:00
#PBS -l nodes=1:ppn=32
#PBS -N myjob


cd ${PBS_O_WORKDIR}
export OMP_NUM_THREADS=32
./myjob &lt; filename.in &gt; filename.out

exit
</code></pre>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class big" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Minimal submit script for LAMMPS GPU job</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="bash">#!/bin/tcsh
#SBATCH --partition=imlab
# Directives can be combined on one line
#SBATCH --time=1:00:00
#SBATCH --nodes=1
# 1 CPU can be be paired with only 1 GPU
# 1 GPU can be paired with all 24 CPUs
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:1
# Need both GPUs, use --gres=gpu:2
#SBATCH --job-name myjob

cd ${SLURM_SUBMIT_DIR}
# Load LAMMPS Module
module load lammps/17nov16-gpu
# Run LAMMPS for input file in.lj
srun $(which lammps) -in in.lj -sf gpu -pk gpu 1 gpuID ${CUDA_VISIBLE_DEVICE}

exit
</code></pre>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Monitoring &amp; Manipulating Jobs</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">SLURM Command</th>
<th align="center">Description</th>
<th align="center">PBS Command</th>
</tr>
</thead><tbody>
<tr>
<td align="center">squeue</td>
<td align="center">check job status (all jobs)</td>
<td align="center">qstat</td>
</tr>
<tr>
<td align="center">squeue -u username</td>
<td align="center">check job status of user <em>username</em></td>
<td align="center">qstat -u username</td>
</tr>
<tr>
<td align="center">squeue --start</td>
<td align="center">Show <strong>estimated</strong> start time of jobs in queue</td>
<td align="center">showstart jobid</td>
</tr>
<tr>
<td align="center">scontrol show job jobid</td>
<td align="center">Check status of your job identified by <em>jobid</em></td>
<td align="center">checkjob jobid</td>
</tr>
<tr>
<td align="center">scancel jobid</td>
<td align="center">Cancel your job identified by <em>jobid</em></td>
<td align="center">qdel jobid</td>
</tr>
<tr>
<td align="center">scontrol hold jobid</td>
<td align="center">Put your job identified by <em>jobid</em> on hold</td>
<td align="center">qhold jobid</td>
</tr>
<tr>
<td align="center">scontrol release jobid</td>
<td align="center">Release the hold that <strong>you put</strong> on <em>jobid</td>
<td align="center">qrls jobid</td>
</tr>
</tbody></table>

<ul>
<li>The following scripts written by RC staff can also be used for monitoring jobs.

<ul>
<li><strong>checkq</strong>: <code>squeue</code> with additional useful option. </li>
<li><strong>checkload</strong>: <code>sinfo</code> with additional options to show load on compute nodes.<br></li>
</ul></li>
<li>load the <code>soltools</code> module to get access to RC staff created scripts</li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Usage Reporting</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><a href="http://slurm.schedmd.com/sacct.html">sacct</a>: displays accounting data for all jobs and job steps in the SLURM job accounting log or Slurm database</li>
<li><p><a href="http://slurm.schedmd.com/sshare.html">sshare</a>: Tool for listing the shares of associations to a cluster. </p></li>
<li><p>We have created scripts based on these to provide usage reporting</p>

<ul>
<li> <code>alloc_summary.sh</code>

<ul>
<li>included in your .bash_profile</li>
<li>prints allocation usage on your login shell</li>
</ul></li>
<li> <code>balance</code>

<ul>
<li>prints allocation usage summary</li>
</ul></li>
<li> <code>solreport</code>

<ul>
<li>obtain your monthly usage report</li>
<li>PIs can obtain usage report for all or specific users on their
allocation</li>
<li>use <code>--help</code> for usage information</li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Need to run multiple jobs in sequence?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Option 1: Submit jobs as soon as previous jobs complete</li>
<li><p>Option 2: Submit jobs with a dependency</p>

<ul>
<li><a href="https://webapps.lehigh.edu/dokuwiki/sites/researchcomputing/doku.php?id=slurm#submitting_dependency_jobs">SLURM</a>:
<code>sbatch --dependency=afterok:&lt;JobID&gt; &lt;Submit Script&gt;</code></li>
<li><a href="https://webapps.lehigh.edu/dokuwiki/sites/researchcomputing/doku.php?id=corona#submitting_dependency_jobs">PBS</a>:
<code>qsub -W depend=afterok:&lt;JobID&gt; &lt;Submit Script&gt;</code></li>
</ul></li>
<li><p>You want to run several serial processor jobs on</p>

<ul>
<li>one node: your submit script should be able to run several serial
jobs in background and then use the <code>wait</code> command for all jobs to finish</li>
<li>more than one node: this requires some background in scripting but the
idea is the same as above</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Additional Help &amp; Information</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Issue with running jobs or need help to get started: 

<ul>
<li>Open a help ticket: <a href="http://go.lehigh.edu/rchelp">http://go.lehigh.edu/rchelp</a></li>
</ul></li>
<li>More Information

<ul>
<li><a href="https://researchcomputing.lehigh.edu">Research Computing</a></li>
<li><a href="https://go.lehigh.edu/rcwiki">Research Computing Wiki</a></li>
<li><a href="https://researchcomputing.lehigh.edu/training">Research Computing Training</a></li>
</ul></li>
<li>Subscribe

<ul>
<li>HPC Training Google Groups: <a href="mailto:hpctraining-list+subscribe@lehigh.edu">hpctraining-list+subscribe@lehigh.edu</a></li>
<li>Research Computing Mailing List: <a href="https://lists.lehigh.edu/mailman/listinfo/hpc-l">https://lists.lehigh.edu/mailman/listinfo/hpc-l</a></li>
</ul></li>
<li>My contact info

<ul>
<li>eMail:  <a href="mailto:alp514@lehigh.edu">alp514@lehigh.edu</a></li>
<li>Tel: (610) 758-6735 </li>
<li>Location: Room 296, EWFM Computing Center</li>
<li><a href="https://www.google.com/calendar/embed?src=alp514%40lehigh.edu&amp;ctz=America/New_York">My Schedule</a></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='About Us?'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='What do we do?'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Training &amp; Consulting'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Full Day Workshops'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Research Computing Resources'>
         5
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=6 title='Research Computing Resources'>
         6
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=7 title='LTS Managed Faculty Resources'>
         7
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=8 title='Total Computational Resources Supported'>
         8
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=9 title='Apply for an account'>
         9
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=10 title='Allocation Charges - Effective Oct. 1, 2016'>
         10
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=11 title='Condo Investments'>
         11
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=12 title='Condo Investors'>
         12
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=13 title='What about Storage resources'>
         13
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=14 title='Network Layout Sol &amp; Ceph Storage Cluster'>
         14
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=15 title='Accessing Research Computing Resources'>
         15
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=16 title='Available Software'>
         16
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=17 title='Installed Software'>
         17
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=18 title='More Software'>
         18
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=19 title='More Software'>
         19
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=20 title='Module Command'>
         20
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=21 title='Creating your own modules'>
         21
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=22 title='Module File Example'>
         22
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=23 title='Compilers'>
         23
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=24 title='Compiling Code'>
         24
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=25 title='Compilers for Parallel Programming: OpenMP &amp; TBB'>
         25
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=26 title='Compilers for Parallel Programming: MPI'>
         26
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=27 title='MPI Libraries'>
         27
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=28 title='Compiling Using Makefiles'>
         28
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=29 title='Makefile Examples'>
         29
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=30 title='Cluster Environment'>
         30
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=31 title='How to run jobs'>
         31
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=32 title='Scheduler &amp; Resource Management'>
         32
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=33 title='Job Scheduling'>
         33
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=34 title='Backfilling'>
         34
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=35 title='How much time must I request'>
         35
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=36 title='Available Queues'>
         36
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=37 title='How much memory can or should I use per core?'>
         37
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=38 title='Useful SBATCH Directives'>
         38
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=39 title='Useful SBATCH Directives (contd)'>
         39
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=40 title='SBATCH Filename Patterns'>
         40
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=41 title='Useful PBS Directives'>
         41
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=42 title='Useful PBS/SLURM environmental variables'>
         42
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=43 title='Basic Job Manager Commands'>
         43
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=44 title='Job Types'>
         44
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=45 title='Job Types: Interactive'>
         45
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=46 title='Job Types: Batch'>
         46
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=47 title='Minimal submit script for Serial Jobs'>
         47
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=48 title='Minimal submit script for MPI Job'>
         48
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=49 title='Minimal submit script for OpenMP Job'>
         49
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=50 title='Minimal submit script for LAMMPS GPU job'>
         50
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=51 title='Monitoring &amp; Manipulating Jobs'>
         51
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=52 title='Usage Reporting'>
         52
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=53 title='Need to run multiple jobs in sequence?'>
         53
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=54 title='Additional Help &amp; Information'>
         54
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  
  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>