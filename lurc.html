<!DOCTYPE html>
<html>
<head>
  <title>Research Computing Resources at Lehigh University</title>
  <meta charset="utf-8">
  <meta name="description" content="Research Computing Resources at Lehigh University">
  <meta name="author" content="https://researchcomputing.lehigh.edu">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  <link rel=stylesheet href="./assets/css/custom.css"></link>
<link rel=stylesheet href="./assets/css/ribbons.css"></link>

  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
        <slide class="title-slide segue nobackground">
  <aside class="gdbar">
    <img src="assets/img/lu.png">
  </aside>
  <hgroup class="auto-fadein">
    <h1>Research Computing Resources at Lehigh University</h1>
    <h2>Library &amp; Technology Services</h2>
    <p>https://researchcomputing.lehigh.edu<br/></p>
  </hgroup>
  <article></article>  
  <footer class = 'license'>
    <a href='http://creativecommons.org/licenses/by-sa/3.0/'>
    <img width = '80px' src = 'http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-sa.png'>
    </a>
  </footer>
</slide>
    

    <!-- SLIDES -->
    <slide class="class" id="slide-1" style="background:#F1E7C8;">
  <hgroup>
    <h2>About Us?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>Who?</p>

<ul>
<li>Unit of Lehigh&#39;s Library &amp; Technology Services within the Center for Innovation in Teaching &amp; Learning</li>
</ul></li>
<li><p>Our Mission</p>

<ul>
<li>We enable Lehigh Faculty, Researchers and Scholars achieve their goals by providing various computational resources; hardware, software, and storage; consulting and training.</li>
</ul></li>
<li><p>Research Computing Staff</p>

<ul>
<li><strong>Alex Pacheco, Manager &#38; XSEDE Campus Champion</strong></li>
<li>Steve Anthony, System Administrator</li>
<li>Dan Brashler, CAS Computing Consultant</li>
<li>Sachin Joshi, Data Analyst &amp; Visualization Specialist</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-2" style="background:#F1E7C8;">
  <hgroup>
    <h2>What do we do?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Hardware Support

<ul>
<li>Provide system administration and support for Lehigh&#39;s HPC clusters.

<ul>
<li>2 University owned and 4 Faculty owned </li>
</ul></li>
<li>Assist with purchase, installation and administration of servers and clusters.</li>
</ul></li>
<li>Data Storage

<ul>
<li>Provide data management services including storing and sharing data. </li>
</ul></li>
<li>Software Support

<ul>
<li>Provide technical support for software applications, install software as requested and assist with purchase of software.</li>
</ul></li>
<li>Training &amp; Consulting

<ul>
<li>Provide education and training programs to facilitate use of HPC resources and general scientific computing needs.</li>
<li>Provide consultation and support for code development and visualization.</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-3" style="background:#F1E7C8;">
  <hgroup>
    <h2>Background and Defintions</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Computational Science and Engineering

<ul>
<li>Gain understanding, mainly through the analysis of mathematical models implemented on computers.</li>
<li>Construct mathematical models and quantitative analysis techniques, using computers to analyze and solve scientific problems.</li>
<li>Typically, these models require large amount of floating-point calculations not possible on desktops and laptops.</li>
<li> The field&#39;s growth drove the need for HPC and benefited from it.</li>
</ul></li>
<li>HPC

<ul>
<li>High Performance Computing (HPC) is computation at the forefront of modern technology, often done on a supercomputer. </li>
</ul></li>
<li>Supercomputer

<ul>
<li> A supercomputer is a computer at the frontline of current processing capacity, particularly speed of calculation.</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-4" style="background:#F1E7C8;">
  <hgroup>
    <h2>Why use HPC?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li> HPC may be the only way to achieve computational goals in a given amount of time

<ul>
<li>Size: Many problems that are interesting to scientists and engineers cannot fit on a PC usually because they need more than a few GB of RAM, or more than a few hundred GB of disk.</li>
<li>Speed: Many problems that are interesting to scientists and engineers would take a very long time to run on a PC: months or even years; but a problem that would take a month on a PC might only take a few hours on a supercomputer</li>
</ul></li>
</ul>

<p><img src="assets/img/irma-at201711_ensmodel_10-5PM.gif" alt="Irma Ensemble
Model" width="225px">
<img src="assets/img/irma-at201711_model-10-5PM.gif" alt="Irma High Probability"
width="225px">
<img src="assets/img/jose-at201712_ensmodel.gif" alt="Jose Ensemble Model"
width="225px">
<img src="assets/img/jose-euro-sep11.png" alt="Jose Euro Model Track Forecast"
width="275px"></p>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-5" style="background:#F1E7C8;">
  <hgroup>
    <h2>Parallel Computing</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>many calculations are carried out simultaneously</li>
<li> based on principle that large problems can often be divided into smaller ones, which are then solved in parallel</li>
<li> Parallel computers can be roughly classified according to the level at which the hardware supports parallelism.

<ul>
<li>Multicore computing</li>
<li> Symmetric multiprocessing</li>
<li> Distributed computing</li>
<li> Grid computing</li>
<li> General-purpose computing on graphics processing units (GPGPU)</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-6" style="background:#F1E7C8;">
  <hgroup>
    <h2>What does HPC do?</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:45%;'>
  <ul>
<li>Simulation of Physical Phenomena

<ul>
<li>Storm Surge Prediction</li>
<li> Black Holes Colliding</li>
<li> Molecular Dynamics</li>
</ul></li>
<li>Data analysis and Mining

<ul>
<li> Bioinformatics</li>
<li> Signal Processing</li>
<li> Fraud detection</li>
</ul></li>
<li>Visualization</li>
</ul>

<p><img src="assets/img/Isaac-Storm-Surge.jpeg" alt="Isaac Storm Surge" width="200px">
<img src="assets/img/Colliding-Black-Holes.jpeg" alt="Colliding Black Holes" width="170px"></p>

</div>
<div style='float:right;width:45%;'>
  <ul>
<li>Design

<ul>
<li> Supersonic ballute</li>
<li> Boeing 787 design</li>
<li> Drug Discovery</li>
<li> Oil Exploration and Production</li>
<li> Automotive Design</li>
<li> Art and Entertainment</li>
</ul></li>
</ul>

<p><img src="assets/img/Molecular-Dynamics.jpeg" alt="Molecular Dynamics" width="200px">
<img src="assets/img/Plane-Design.jpg" alt="Plane Design" width="200px"></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-7" style="background:#F1E7C8;">
  <hgroup>
    <h2>HPC by Disciplines</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Traditional Disciplines

<ul>
<li>Science: Physics, Chemistry, Biology, Material Science</li>
<li>Engineering: Mechanical, Structural, Civil, Environmental, Chemical</li>
</ul></li>
<li>Non Traditional Disciplines

<ul>
<li>Finance

<ul>
<li>Preditive Analytics</li>
<li>Trading</li>
</ul></li>
<li>Humanities

<ul>
<li>Culturomics or cultural analytics: study human behavior and cultural trends through quantitative analysis of digitized texts, images and videos.</li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-8" style="background:#F1E7C8;">
  <hgroup>
    <h2>Research Computing Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p><strong> Maia </strong></p>

<ul>
<li>32-core Symmetric Multiprocessor (SMP) system available to all Lehigh Faculty, Staff and Students</li>
<li>dual 16-core AMD Opteron 6380 2.5GHz CPU</li>
<li>128GB RAM and 4TB HDD</li>
<li>Theoretical Performance: 640 GFLOPs (640 billion floating point operations per second)</li>
<li>Access: Batch Scheduled, no interactive access to Maia</li>
</ul>

<p>\[
GFLOPs = cores \times clock \times \frac{FLOPs}{cycle}
\]</p>

<p><a href="https://en.wikipedia.org/wiki/FLOPS#FLOPs_per_cycle">FLOPs for various AMD &amp; Intel CPU generation</a></p>

<ul>
<li><code>Currently out of warranty</code>. </li>
<li><code>Will be permanently shut down in case of hardware failure</code></li>
<li><code>No plans to replace Maia</code></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-9" style="background:#F1E7C8;">
  <hgroup>
    <h2>Research Computing Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><strong> Sol </strong>

<ul>
<li>Lehigh&#39;s Flagship High Performance Computing Cluster</li>
<li>9 nodes, dual 10-core Intel Xeon E5-2650 v3 2.3GHz CPU, 25MB Cache, 128GB
RAM</li>
<li>33 nodes, dual 12-core Intel Xeon E5-2670 v3 2.3Ghz CPU, 30 MB Cache,
128GB RAM</li>
<li>14 nodes, dual 12-core Intel Xeon E5-2650 v4 2.3Ghz CPU, 30 MB Cache, 64GB
RAM</li>
<li>1 node, dual 8-core Intel Xeon 2630 v3 2.4GHz CPU, 20 MB Cache, 512GB RAM</li>
<li>23 nodes, dual 18-core Intel Xeon Gold 6140 2.3GHz CPU, 24.7 MB Cache, 192GB RAM</li>
<li>66 nVIDIA GTX 1080 GPU cards</li>
<li>48 nVIDIA RTX 2080TI GPU cards</li>
<li>1TB HDD per node</li>
<li>2:1 oversubscribed Infiniband EDR (100Gb/s) interconnect fabric</li>
<li>Theoretical Performance: 81.088 TFLOPs (CPU) + 34.588 TFLOPs (GPU)</li>
<li>Access: Batch Scheduled, interactive on login node for compiling, editing
only</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Sol</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:50%;'>
  <p><img class="fullwidth" src='assets/img/sol/20160509_140506.jpg'></p>

</div>
<div style='float:right;width:48%;'>
  <p><img class="fullwidth" src='assets/img/sol/20160509_141134.jpg'></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Sol</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:50%;'>
  <p><img class="fullwidth" src='assets/img/sol/20160627_153416.jpg'></p>

</div>
<div style='float:right;width:48%;'>
  <p><img class="fullwidth" src='assets/img/sol/20160509_133642.jpg'></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Sol</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:50%;'>
  <p><img class="fullwidth" src='assets/img/sol/20171011_104200.jpg'></p>

</div>
<div style='float:right;width:48%;'>
  <p><img class="fullwidth" src='assets/img/sol/20170301_112522.jpg'></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>Network Layout Sol &amp; Ceph Storage Cluster</h2>
  </hgroup>
  <article data-timings="">
    <p><img class="fullwidth" src='assets/img/hpcnetwork.png'></p>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:#F1E7C8;">
  <hgroup>
    <h2>LTS Managed Faculty Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><strong>Monocacy</strong>: Ben Felzer, Earth &amp; Environmental Sciences

<ul>
<li>Eight nodes, dual 8-core Intel Xeon E5-2650v2, 2.6GHz, 64GB RAM

<ul>
<li>Theoretical Performance: 2.662TFlops</li>
</ul></li>
</ul></li>
<li><strong>Baltrusaitislab</strong>: Jonas Baltrusaitis, Chemical Engineering

<ul>
<li>Three nodes, dual 16-core AMD Opteron 6376, 2.3Ghz, 128GB RAM

<ul>
<li>Theoretical Performance: 1.766TFlops</li>
</ul></li>
</ul></li>
<li><strong>Pisces</strong>: Keith Moored, Mechanical Engineering and Mechanics

<ul>
<li>Six nodes, dual 10-core Intel Xeon E5-2650v3, 2.3GHz, 64GB RAM, nVIDIA Tesla K80

<ul>
<li>Theoretical Performance: 3.840 TFlops (CPU) + 17.46TFlops (GPU)</li>
</ul></li>
</ul></li>
<li>Devel/Testing : decommissioned faculty cluster for prototyping new resources

<ul>
<li>Twenty nodes, dual 8-core Intel Xeon E5-2650v2, 2.6GHz, 64GB RAM

<ul>
<li>Theoretical Performance: 6.656TFlops</li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-15" style="background:#F1E7C8;">
  <hgroup>
    <h2>Total Computational Resources Supported</h2>
  </hgroup>
  <article data-timings="">
    <table><thead>
<tr>
<th align="center">Cluster</th>
<th align="center">Cores</th>
<th align="center">CPU Memory</th>
<th align="center">CPU TFLOPs</th>
<th align="center">GPUs</th>
<th align="center">CUDA Cores</th>
<th align="center">GPU Memory</th>
<th align="center">GPU TFLOPS</th>
</tr>
</thead><tbody>
<tr>
<td align="center">Maia</td>
<td align="center">32</td>
<td align="center">128</td>
<td align="center">0.640</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Monocacy</td>
<td align="center">128</td>
<td align="center">512</td>
<td align="center">2.662</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Devel</td>
<td align="center">320</td>
<td align="center">1280</td>
<td align="center">6.656</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Baltrusaitislab</td>
<td align="center">96</td>
<td align="center">384</td>
<td align="center">1.766</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Pisces</td>
<td align="center">120</td>
<td align="center">384</td>
<td align="center">3.840</td>
<td align="center">12</td>
<td align="center">29952</td>
<td align="center">144</td>
<td align="center">17.472</td>
</tr>
<tr>
<td align="center">Sol</td>
<td align="center">2152</td>
<td align="center">11200</td>
<td align="center">81.088</td>
<td align="center">114</td>
<td align="center">377856</td>
<td align="center">1056</td>
<td align="center">34.588</td>
</tr>
<tr>
<td align="center">Total</td>
<td align="center">2848</td>
<td align="center">13888</td>
<td align="center">96.652</td>
<td align="center">126</td>
<td align="center">407808</td>
<td align="center">1200</td>
<td align="center">52.060</td>
</tr>
</tbody></table>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-16" style="background:#F1E7C8;">
  <hgroup>
    <h2>Apply for an account</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><a href="https://idmweb.cc.lehigh.edu/accounts/?page=hpc">Apply for an account at the LTS website</a>

<ul>
<li>Click on Services &gt; Account &amp; Password &gt; Lehigh Computing Account &gt; Request an account</li>
<li>Click on the big blue button &quot;Start Special Account Request&quot; &gt; Research Computing Account </li>
<li>Maia

<ul>
<li>Click on &quot;FREE Linux command-line computing&quot;</li>
</ul></li>
<li>Sol: PIs should contact Alex Pacheco or Steve Anthony, web request is not functional

<ul>
<li>Annual charge of $50/account paid by Lehigh Faculty or Research Staff, and</li>
<li>Annual charge for computing time</li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-17" style="background:#F1E7C8;">
  <hgroup>
    <h2>Allocation Charges - Effective Oct. 1, 2016</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Cost per core-hour or service unit (SU) is 1&cent;</li>
<li><p>SU is defined as 1 hour of computing on 1 core of the Sol base compute node.</p>

<ul>
<li>One base compute node of Sol consumes 20 SU/hour, 480 SU/day and 175,200 SU/year</li>
</ul></li>
<li><p>PIs can share allocations with their collaborators</p>

<ul>
<li>Minimum Annual Purchase of 50,000 SU - &#36;500/year</li>
<li>Additional Increments of 10,000 SU - &#36;100 per 10K increments</li>
<li>Fixed Allocation cycle: Oct 1 - Sep 30</li>
<li>Unused allocations do not rollover to next allocation cycle</li>
<li>Total available computing time for purchase annually: 1.4M SUs or 1 year of continous computing on 8 nodes</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-18" style="background:#F1E7C8;">
  <hgroup>
    <h2>Example Allocation Request</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>PI requires 100K SUs of computing time per year
<ul class="unilist">
<li><span class="unibull">&#x2776;</span> One Purchase:
 <ul><li> 100K SU for &#36;1000/year</li></ul>
</li>
<li><span class="unibull">&#x2777;</span>Multiple Purchases:
 <ul><li> Initial 50K SUs for &#36;500/year.</li>
 <li> Multiple additional purchases of 10K SUs for &#36;100 each as required.</li></ul>
</li>
</ul></li>
<li><p>All 100K SUs (<span class="txtbull">&#x2776;</span> and <span class="txtbull">&#x2777;</span>) must be used up by Sep. 30 of next year.</p>

<ul>
<li>If rolling allocation cycle is implemented, then all 100K SUs (<span class="txtbull">&#x2776;</span> and <span class="txtbull">&#x2777;</span>) must be used up within 1 year of initial 50K purchase.</li>
</ul></li>
<li><p>Need more than 175K SU/year or</p></li>
<li><p>BECOME A CONDO INVESTOR</p></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-19" style="background:#F1E7C8;">
  <hgroup>
    <h2>Condo Investments</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>New sustainable model for High Performance Computing at Lehigh</li>
<li>Faculty (Condo Investor) purchase compute nodes from grants to increase overall capacity of Sol</li>
<li>LTS will provide for four years or length of hardware warranty purchased.

<ul>
<li>System Administration, Power and Cooling, User Support for Condo Investments</li>
</ul></li>
<li>Condo Investor

<ul>
<li>receives annual allocation equivalent to their investment for the length of
investment</li>
<li>can utilize allocations on all available nodes, including nodes from other Condo Investors</li>
<li>allows idle cycles on investment to be used by other Sol users</li>
<li>unused allocation will not rollover to the next allocation cycle.</li>
<li>can purchase additional SUs in 10K increments (minimum 50K not required)

<ul>
<li> and must be consumed in current allocation cycle</li>
</ul></li>
</ul></li>
<li>Annual Allocation cycle is Oct. 1 - Sep. 30.</li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-20" style="background:#F1E7C8;">
  <hgroup>
    <h2>Condo Investors</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>Two at initial launch </p>

<ul>
<li>Dimitrios Vavylonis, Physics (1 node)</li>
<li>Wonpil Im, Biological Sciences (37 nodes, 98 GPUs)</li>
<li>Anand Jagota, Chemical Engineering (1 node)</li>
<li>Brian Chen, Computer Science &amp; Engineering (1 node)</li>
<li>Ed Webb &amp; Alp Oztekin, Mechanical Engineering (6 nodes)</li>
<li>Jeetain Mittal &amp; Srinivas Rangarajan, Chemical Engineering (13 nodes, 16 GPUs)</li>
<li>Seth Richards-Shubik, Economics (1 node)</li>
<li>Ganesh Balasubramanian, Mechanical Engineering (7 nodes)</li>
<li>Department of Industrial &amp; Systems Engineering (2 nodes)</li>
<li>Paolo Bocchini, Civil and Structural Engineering (1 node)</li>
<li>Lisa Fredin, Chemistry (2 nodes)</li>
</ul></li>
<li><p>Total SU on Sol after Condo Investments: 18,851,520</p></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-21" style="background:#F1E7C8;">
  <hgroup>
    <h2>Storage resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>LTS provides various storage options for research and teaching..</li>
<li>Some are cloud based and subject to Lehigh&#39;s Cloud Policy</li>
<li>For research, LTS provides a 618TB storage system called Ceph</li>
<li>Ceph is based on the Ceph software</li>
<li>Research groups can purchase a sharable project space on Ceph @ &#36;375/TB
with a 5 year duration</li>
<li>Ceph is in-house, built, operated and administered by LTS Research Computing Staff.

<ul>
<li>located in Data Center in EWFM with a backup cluster in Packard Lab</li>
</ul></li>
<li>HPC users can write job output directly to their Ceph volume</li>
<li>Ceph volume can be mounted as a network drive on Windows or CIFS on Mac and Linux

<ul>
<li><a href="http://lts.lehigh.edu/services/faq/ceph-faq">See Ceph FAQ</a> for more details</li>
</ul></li>
<li>Annual HPC User account fees waived for PIs who purchase a 1TB Ceph space for life
of Ceph i.e. 5 years </li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-22" style="background:#F1E7C8;">
  <hgroup>
    <h2>Data Transfer, ScienceDMZ and Globus</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>NSF funded Science DMZ to improve campus connectivity to the national research cyberinfrastructure.</li>
<li>Upto 50TB storage is available on the Data Transfer Node (DTN) on ScienceDMZ.

<ul>
<li>Storage space is only for data transfer. Once transfer is complete, storage needs to be deleted from DTN</li>
</ul></li>
<li>Access to DTN with shell access provided on request</li>
<li><a href="https://www.globus.org">Globus</a> is the preferred method to transfer data to and from NSF and DOE supercomputing centers.

<ul>
<li>hosted service that manages the entire operation, monitoring performance and errors, retrying failed transfers, correcting problems automatically whenever possible, and reporting status to keep you informed while you focus on your research.</li>
<li><a href="https://researchcomputing.lehigh.edu/help/globus">How to Use Globus at Lehigh?</a></li>
<li>No special access required on DTN to transfer data via Globus</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-23" style="background:#F1E7C8;">
  <hgroup>
    <h2>Sol, Maia  &amp; Ceph for Courses</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Research Computing Resources; Sol, Maia &amp; Ceph are available for use in registrar scheduled classes.</li>
<li><strong>Maia</strong>: No charge, no special considerations</li>
<li><strong>Sol</strong>: Provides<br>

<ul>
<li>1TB Ceph space per course (&#36;100 paid by department)</li>
<li>An account per student (&#36;15/student) paid by department that provides 500SUs per student

<ul>
<li>Allocations are given for the whole class based on number of students</li>
<li>Additional allocations can be purchased in blocks of 1000 SUs @ $10/block upto 10K SU</li>
</ul></li>
<li>Accounts valid for current semester plus an additional two weeks</li>
</ul></li>
<li><strong>Ceph</strong>: 

<ul>
<li>&#36;100 per TB per course.</li>
<li>Paid for by department.</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-24" style="background:#F1E7C8;">
  <hgroup>
    <h2>Accessing Research Computing Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>All Research Computing resources are accessible using ssh while on Lehigh&#39;s network</li>
<li>Sol: <code>ssh username@sol.cc.lehigh.edu</code></li>
<li>Maia: No direct access to Maia, instead login to the polaris</li>
<li>Polaris: <code>ssh username@polaris.cc.lehigh.edu</code>

<ul>
<li>Polaris is a gateway that also hosts the batch scheduler for Maia.</li>
<li>No computing software including compilers is available on Polaris.</li>
<li>Login to Polaris and request computing time on Maia including interactive access.</li>
</ul></li>
<li>If you are not on Lehigh&#39;s network, login to the ssh gateway to get to Research Computing resources.

<ul>
<li><code>ssh username@ssh.cc.lehigh.edu</code></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-25" style="background:#F1E7C8;">
  <hgroup>
    <h2>Available Software</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Commercial, Free and Open source software is installed on

<ul>
<li><a href="https://webapps.lehigh.edu/dokuwiki/sites/researchcomputing/doku.php?id=maia#installed_software">Maia</a>: /zhome/Apps</li>
<li><a href="https://webapps.lehigh.edu/dokuwiki/sites/researchcomputing/doku.php?id=sol#installed_software">Sol</a>: /share/Apps</li>
</ul></li>
<li>Software is managed using module environment

<ul>
<li>Why? We may have different versions of same software or software built with different compilers</li>
<li>Module environment allows you to dynamically change your &#42;nix environment based on software being used</li>
<li>Standard on many University and national High Performance Computing resource since circa 2011</li>
</ul></li>
<li>How to use Sol/Maia Software on your <a href="https://webapps.lehigh.edu/dokuwiki/sites/researchcomputing/doku.php?id=linux">linux</a> workstation</li>
<li>LTS provides <a href="https://software.lehigh.edu">licensed and open source software</a> for Windows, Mac and Linux and <a href="https://gogs.cc.lehigh.eu">Gogs</a>, a self hosted Git Service or Github clone</li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-26" style="background:#F1E7C8;">
  <hgroup>
    <h2>Installed Software</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:45%;'>
  <ul>
<li>Chemistry/Materials Science

<ul>
<li><strong>CPMD</strong></li>
<li><strong>GAMESS</strong></li>
<li>Gaussian</li>
<li><strong>NWCHEM</strong></li>
<li><strong>Quantum Espresso</strong></li>
<li><strong>VASP</strong> (Restricted Access)</li>
</ul></li>
<li>Molecular Dynamics

<ul>
<li><strong>Desmond</strong></li>
<li><strong>GROMACS</strong></li>
<li><strong>LAMMPS</strong></li>
<li><strong>NAMD</strong></li>
</ul></li>
</ul>

<p><span class="tiny strong"><strong>MPI enabled</strong></span></p>

</div>
<div style='float:right;width:45%;'>
  <ul>
<li>Computational Fluid Dynamics

<ul>
<li>Abaqus</li>
<li>Ansys</li>
<li>Comsol</li>
<li><strong>OpenFOAM</strong></li>
<li>OpenSees</li>
</ul></li>
<li>Math

<ul>
<li>GNU Octave</li>
<li>Magma</li>
<li>Maple</li>
<li>Mathematica</li>
<li>Matlab</li>
</ul></li>
</ul>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-27" style="background:#F1E7C8;">
  <hgroup>
    <h2>More Software</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:45%;'>
  <ul>
<li><p><em>Machine &amp; Deep Learning</em> </p>

<ul>
<li>TensorFlow</li>
<li>Caffe</li>
<li>SciKit-Learn</li>
<li>SciKit-Image</li>
<li>Theano</li>
<li>Keras</li>
</ul></li>
<li><p><em>Natural Language Processing (NLP)</em></p>

<ul>
<li>Natural Language Toolkit (NLTK)</li>
<li>Stanford NLP<br></li>
</ul></li>
</ul>

<p><span class="tiny"><em><a href="https://go.lehigh.edu/python">Python packages</a></em></span></p>

</div>
<div style='float:right;width:45%;'>
  <ul>
<li>Bioinformatics

<ul>
<li>BamTools</li>
<li>BayeScan</li>
<li>bgc</li>
<li>BWA</li>
<li>FreeBayes</li>
<li>SAMTools</li>
<li>tabix</li>
<li>trimmomatic</li>
<li><em>barcode_splitter</em></li>
<li><em>phyluce</em> </li>
<li><em>VelvetOptimiser</em></li>
</ul></li>
</ul>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-28" style="background:#F1E7C8;">
  <hgroup>
    <h2>More Software</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:35%;'>
  <ul>
<li>Scripting Languages

<ul>
<li>R</li>
<li>Perl</li>
<li>Python</li>
</ul></li>
<li>Compilers

<ul>
<li>GNU</li>
<li>Intel</li>
<li>JAVA</li>
<li>PGI</li>
<li>CUDA</li>
</ul></li>
<li>Parallel Programming

<ul>
<li>MVAPICH2</li>
<li>OpenMPI</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:65%;'>
  <ul>
<li>Libraries

<ul>
<li>BLAS/LAPACK/GSL/SCALAPACK</li>
<li>Boost</li>
<li>FFTW</li>
<li>Intel MKL</li>
<li>HDF5</li>
<li>NetCDF</li>
<li>METIS/PARMETIS</li>
<li>PetSc</li>
<li>QHull/QRupdate</li>
<li>SuiteSparse</li>
<li>SuperLU</li>
</ul></li>
</ul>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-29" style="background:#F1E7C8;">
  <hgroup>
    <h2>More Software</h2>
  </hgroup>
  <article data-timings="">
    
<div style='float:left;width:45%;'>
  <ul>
<li>Visualization Tools

<ul>
<li>Atomic Simulation Environment </li>
<li>Avogadro</li>
<li>GaussView</li>
<li>GNUPlot</li>
<li>PWGui</li>
<li>PyMol</li>
<li>RDKit</li>
<li>VESTA</li>
<li>VMD</li>
<li>XCrySDen</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:45%;'>
  <ul>
<li>Other Tools

<ul>
<li>Artleys Knitro</li>
<li>ROOT</li>
<li>CMake</li>
<li>GNU Parallel</li>
<li>Lmod</li>
<li><em>Numba</em></li>
<li>Scons</li>
<li>SPACK</li>
<li><em>MD Tools</em>

<ul>
<li>BioPython</li>
<li>CCLib</li>
<li>MDAnalysis</li>
</ul></li>
</ul></li>
</ul>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-30" style="background:#F1E7C8;">
  <hgroup>
    <h2>Using your own Software?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>You can always install a software in your home directory

<ul>
<li><a href="https://spack.readthedocs.io">SPACK</a> is an excellent package manager that can even create module files</li>
</ul></li>
<li><code>Stay compliant with software licensing</code></li>
<li>Modify your .bashrc/.tcshrc to add software to your path, OR</li>
<li>create a module and dynamically load it so that it doesn&#39;t interfere 
with other software installed on the system

<ul>
<li>e.g. You might want to use openmpi instead of mvapich2 </li>
<li>the system admin may not want install it system wide for just one user</li>
</ul></li>
<li>Add the directory where you will install the module files to the variable 
MODULEPATH in .bashrc/.tcshrc</li>
</ul>

<pre><code class="sh"># My .bashrc file
export MODULEPATH=${MODULEPATH}:/home/alp514/modulefiles
</code></pre>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-31" style="background:#F1E7C8;">
  <hgroup>
    <h2>Module File Example</h2>
  </hgroup>
  <article data-timings="">
    <p><img width = '900px' src = 'assets/img/mcr.png'></p>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-32" style="background:#F1E7C8;">
  <hgroup>
    <h2>How to run jobs</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>All compute intensive jobs are batch scheduled</li>
<li>Write a script to submit jobs to a scheduler

<ul>
<li>need to have some background in shell scripting (bash/tcsh)</li>
</ul></li>
<li>Need to specify

<ul>
<li>Resources required (which depends on configuration)

<ul>
<li>number of nodes</li>
<li>number of processes per node</li>
<li>memory per node</li>
</ul></li>
<li>How long do you want the resources

<ul>
<li>have an estimate for how long your job will run</li>
</ul></li>
<li>Which queue to submit jobs</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-33" style="background:#F1E7C8;">
  <hgroup>
    <h2>Batch Queuing System</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>A software that manages resources (CPU time, memory, etc) and schedules job execution</p>

<ul>
<li>Sol: Simple Linux Utility for Resource Management (SLURM)</li>
<li>Others:  Portable Batch System (PBS)

<ul>
<li>Scheduler: Maui</li>
<li>Resource Manager: Torque</li>
<li>Allocation Manager: Gold</li>
</ul></li>
</ul></li>
<li><p>More details in upcoming HPC Training on <a href="https://webapps.lehigh.edu/hpc/training/lurc/slurm.html">SLURM</a></p></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-34" style="background:#F1E7C8;">
  <hgroup>
    <h2>XSEDE</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>The E<b>x</b>treme <b>S</b>cience and <b>E</b>ngineering <b>D</b>iscovery <b>E</b>nvironment (<strong>XSEDE</strong>) is the most advanced, powerful, and robust collection of integrated advanced digital resources and services in the world. </p></li>
<li><p>It is a single virtual system that scientists can use to interactively share computing resources, data, and expertise.</p></li>
<li><p>Scientists and engineers around the world use these resources and services—things like supercomputers, collections of data, and new tools—to make our lives healthier, safer, and better. </p></li>
<li><p>XSEDE, and the experts who lead the program, will make these resources easier to use and help more people use them.</p></li>
</ul>

<div style='float:left;width:60%;'>
  <ul>
<li><p>The five-year, &#36;121-million project is supported by the National Science Foundation. </p></li>
<li><p>It replaces and expands on the NSF TeraGrid project.</p></li>
</ul>

</div>
<div style='float:right;width:40%;'>
  <p><img width = '400px' src = 'assets/img/xsede.png'></p>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-35" style="background:#F1E7C8;">
  <hgroup>
    <h2>XSEDE Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>XSEDE is composed of multiple partner institutions known as Service Providers or SPs, each of which contributes one or more allocatable services. </p></li>
<li><p>Resources include High Performance Computing (HPC) machines, High Throughput Computing (HTC) machines, visualization, data storage, testbeds, and services. </p></li>
<li><p>Texas Advanced Computing Center (TACC) </p>

<ul>
<li>Stampede2: 18 PFlops </li>
<li>Wrangler for Data Analytics: 62 TFLops

<ul>
<li>0.5PB high speed flash storage</li>
<li>10PB file system at TACC and IU</li>
</ul></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-36" style="background:#F1E7C8;">
  <hgroup>
    <h2>XSEDE Resources</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>San Diego Supercomputing Center (SDSC) </p>

<ul>
<li>Comet: 2 PFlops</li>
</ul></li>
<li><p>Indiana University </p>

<ul>
<li>Jetstream: Cloud Computing Environment for IaaS, Paas and SaaS

<ul>
<li>516 TFlops and 2 PB block and object storage</li>
</ul></li>
</ul></li>
<li><p>Pittsburgh Supercomputing Center</p>

<ul>
<li>Bridges: 894 Flops and 144 TiB RAM </li>
</ul></li>
<li><p>Open Science Grid: 50 TFLOPs</p></li>
</ul>

<!--
<img width = '400px' src = 'assets/img/xsede.png'>
-->

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-37" style="background:#F1E7C8;">
  <hgroup>
    <h2>How do I get started on XSEDE?</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Apply for an account at the <a href="https://portal.xsede.org">XSEDE Portal</a>.</li>
<li>There is no charge to get an XSEDE portal account.<br></li>
<li>You need a portal account to register for XSEDE Tutorials and Workshops</li>
<li>To use XSEDE&#39;s compute and data resources, you need to have an allocation.</li>
<li>An allocation on a particular resource activates your account on that allocation.</li>
<li>Researchers and Educators from US universities and federal research labs can 
serve as Principle Investigators on XSEDE allocation.</li>
<li>A PI can add students to his/her allocations.</li>
<li>XSEDE also has a Campus Champion Program</li>
<li>A XSEDE Campus Champion is a local source of knowledge about high-performance 
and high-throughput computing and other digital services, opportunities and resources. </li>
<li>A Campus Champion can request start up allocations on all XSEDE resources to help 
local users with getting started on XSEDE resources.</li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-38" style="background:#F1E7C8;">
  <hgroup>
    <h2>National Science Foundation (NSF)</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>In addition to XSEDE, NSF also provides BlueWaters, a petascale supercomputer at the National Center for Supercomputing Applications (NCSA) at the University of Illinois at Urbana-Champaign</li>
<li>heterogenous Cray XE6/XK7 

<ul>
<li>22,000 XE6 compute nodes (each containing two AMD Interlagos processors) </li>
<li>more than 4000 XK7 compute nodes (each containing one AMD Interlagos processor and one NVIDIA GK110 &quot;Kepler&quot; accelerator) </li>
<li>single high-speed Gemini interconnection fabric.</li>
</ul></li>
<li>150M node-hours allocated every year through the NSF&#39;s <a href="https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=503224&amp;org=OCI&amp;from=home">Petascale Computing Resource Allocation program</a></li>
<li>To be replaced with 38PFLOP <a href="https://www.tacc.utexas.edu/systems/frontera">Frontera</a> cluster located at Texas Advanced
Computing Center.

<ul>
<li>It&#39;s unknown how this cluster will be allocated since it&#39;s life exceeds
the life of XSEDE 2.0 </li>
<li>NSF rules prohibit a project to exceed 10 years, so next iteration of
XSEDE needs to have a different project name.<br></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-39" style="background:#F1E7C8;">
  <hgroup>
    <h2>Department of Energy (DOE)</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Innovative and Novel Computational Impact on Theory and Experiment (<a href="https://proposals.doeleadershipcomputing.org">INCITE</a>) program open to researchers from academia, government labs, and industry

<ul>
<li>proposals are accepted between mid-April and the end of June </li>
<li>Argonne Leadership Computing Facility 

<ul>
<li>184M node hours on Mira, 10 PFLOPs IBM Blue Gene/Q system </li>
<li>13.5M node hours on Theta, 11PFLOPs Cray XC40 system</li>
</ul></li>
<li>Oak Ridge Leadership Computing Facility

<ul>
<li>16M node hours on Summit, 187 PFLOPs IBM Power9 system</li>
<li>56M node hours on Titan, 27 PFLOPs Cray XK7 system </li>
</ul></li>
</ul></li>
<li>National Energy Research Scientific Computing (NERSC) Center at Lawrence Berkeley National Lab.

<ul>
<li>Mostly for DOE sponsored research</li>
<li><a href="http://www.nersc.gov/users/accounts/allocations/first-allocation/">Get Started</a></li>
<li>Allocations will be reduced if not used within an allocation cycle. </li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-40" style="background:#F1E7C8;">
  <hgroup>
    <h2>National Center for Atmospheric Research (NCAR)</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>The Computational and Information Systems Laboratory (CISL) provides large computing resources for university researchers and NCAR scientists in atmospheric and related sciences.</li>
<li>Cheyenne, a 5.34 PFlops HPC system, provides more than 1.2 billion core-hours for allocation each year</li>
<li>Access granted through a variety of programs</li>
<li>University Allocations

<ul>
<li>Large requests &gt;400K SUs: Requests accepted every six months, in March
and September. 160M SUs awarded in total each allocation cycle</li>
<li>Small requests &lt;400K SUs: U.S. university researchers who are supported by NSF awards can request a small allocation for each NSF award. Requests accepted throughout the year and reviewed/awarded within a few business days.</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-41" style="background:#F1E7C8;">
  <hgroup>
    <h2>NCAR - CISL (contd)</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Unsponsored Graduate Students and Postdocs: Small allocations are also available to graduate students and post-docs at U.S. universities; no NSF award or panel review is required.

<ul>
<li>The graduate student, postdoc, or faculty member must work in the atmospheric or related sciences;</li>
<li>Their work does not lie within the scope of an associated NSF grant; and</li>
<li>They do not have funding to pay for computer time.</li>
</ul></li>
<li>Classroom Allocation

<ul>
<li>CISL offers opportunities to undergraduate and graduate faculty to use high-performance computers in their college courses. </li>
<li>Accounts are provided to individual students and the professor for assignments in numerical simulations, modeling, and studies of recently introduced computing architectures. </li>
<li>CISL can provide consulting assistance to the professor or teaching assistant.</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-42" style="background:#F1E7C8;">
  <hgroup>
    <h2>NCAR - CSL</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Climate Simulation Laboratory 

<ul>
<li>Researchers must have funding from NSF awards to address the climate-related questions</li>
<li>submission deadline is March 26, 2018</li>
<li>minimum request is 20M SUs</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-43" style="background:#F1E7C8;">
  <hgroup>
    <h2>HPC Seminars</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>RC staff also guest lecture for various courses and provide various training
seminars in collaboration with other LTS groups</li>
</ul>

<div style='float:left;width:50%;'>
  <ul>
<li>Research Computing at Lehigh </li>
<li>Linux: Basic Commands &amp; Environment </li>
<li>Using SLURM scheduler on Sol</li>
<li>Shell Scripting </li>
<li>Python Programming</li>
<li>Data Visualization</li>
<li>RefWorks</li>
<li>Document Creation with LaTeX </li>
<li>Using Virtualized Software at Lehigh </li>
</ul>

</div>
<div style='float:right;width:48%;'>
  <ul>
<li>A Brief Introduction to Linux </li>
<li>Storage Options at Lehigh </li>
<li>Research Data Management</li>
<li>Version Control with GIT</li>
<li>Programming in MATLAB and GNU Octave</li>
<li>Programming in R</li>
<li>Enhancing Research Impact</li>
<li>Parallel Programming Concepts </li>
<li>Saltstack Config Management</li>
</ul>

</div>
  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-44" style="background:#F1E7C8;">
  <hgroup>
    <h2>Workshops</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>During the summer we provide full day workshops on programming topics</li>
<li>Summer 2015 Workshops

<ul>
<li>Modern Fortran Programming</li>
<li>C Programming</li>
</ul></li>
<li>HPC Parallel Programming Workshop (Summer 2017, 2018)

<ul>
<li>Programming in MPI, OpenMP and OpenACC</li>
</ul></li>
<li>We also host full day workshops broadcast from other Supercomputing Centers

<ul>
<li>XSEDE HPC Monthly Workshop: OpenACC (Dec. 2014)</li>
<li>XSEDE HPC Summer BootCamp: OpenMP, OpenACC, MPI and Hybrid Programming (Jun.
2015 - 2018)</li>
<li>XSEDE HPC Monthly Workshop: Big Data (Nov. 2015, May 2017)</li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-45" style="background:#F1E7C8;">
  <hgroup>
    <h2>Upcoming HPC Seminars</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>EWFM 292 on Thursday from 2:10PM - 4:00PM.</p>

<ul>
<li>Using SLURM scheduler on Sol (Feb 14)</li>
<li>Document Creation with LaTeX (Feb 21)</li>
<li>Programming in R (Feb 28)</li>
<li>Data Visualization in R (Mar 7)</li>
<li>Python Programming (Mar 21)</li>
<li>Data Visualization in Python (Mar 28)</li>
</ul></li>
<li><p>Subscribe</p>

<ul>
<li>Research Computing Mailing List: <a href="https://lists.lehigh.edu/mailman/listinfo/hpc-l">https://lists.lehigh.edu/mailman/listinfo/hpc-l</a></li>
<li>HPC Training Google Groups: <a href="mailto:hpctraining-list+subscribe@lehigh.edu">hpctraining-list+subscribe@lehigh.edu</a></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="slide-46" style="background:#F1E7C8;">
  <hgroup>
    <h2>Getting Help</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Issue with running jobs or need help to get started: 

<ul>
<li>Open a help ticket: <a href="http://lts.lehigh.edu/help">http://lts.lehigh.edu/help</a></li>
</ul></li>
<li>Investing in Sol

<ul>
<li>Contact Alex Pacheco or Steve Anthony</li>
</ul></li>
<li>More Information

<ul>
<li><a href="http://researchcomputing.lehigh.edu/services/condo">Condo Program and Available Equipment</a></li>
<li><a href="http://researchcomputing.lehigh.edu/services/proposalassist">Proposal Assistance</a></li>
<li><a href="http://libraryguides.lehigh.edu/researchdatamanagement">Data Management Plans</a></li>
<li><a href="https://researchcomputing.lehigh.edu">Research Computing</a></li>
<li><a href="https://go.lehigh.edu/rcwiki">Research Computing Wiki</a></li>
<li><a href="https://researchcomputing.lehigh.edu/training">Research Computing Training</a></li>
</ul></li>
</ul>

  </article>
  <!-- Footer  -->
  <footer class = 'lufoot'>
     <img height = '20px' src='assets/img/lulogo.jpg'>
  </footer>
  <!-- End Footer-->
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='About Us?'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='What do we do?'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Background and Defintions'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Why use HPC?'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Parallel Computing'>
         5
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=6 title='What does HPC do?'>
         6
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=7 title='HPC by Disciplines'>
         7
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=8 title='Research Computing Resources'>
         8
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=9 title='Research Computing Resources'>
         9
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=10 title='Sol'>
         10
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=11 title='Sol'>
         11
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=12 title='Sol'>
         12
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=13 title='Network Layout Sol &amp; Ceph Storage Cluster'>
         13
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=14 title='LTS Managed Faculty Resources'>
         14
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=15 title='Total Computational Resources Supported'>
         15
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=16 title='Apply for an account'>
         16
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=17 title='Allocation Charges - Effective Oct. 1, 2016'>
         17
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=18 title='Example Allocation Request'>
         18
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=19 title='Condo Investments'>
         19
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=20 title='Condo Investors'>
         20
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=21 title='Storage resources'>
         21
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=22 title='Data Transfer, ScienceDMZ and Globus'>
         22
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=23 title='Sol, Maia  &amp; Ceph for Courses'>
         23
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=24 title='Accessing Research Computing Resources'>
         24
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=25 title='Available Software'>
         25
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=26 title='Installed Software'>
         26
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=27 title='More Software'>
         27
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=28 title='More Software'>
         28
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=29 title='More Software'>
         29
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=30 title='Using your own Software?'>
         30
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=31 title='Module File Example'>
         31
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=32 title='How to run jobs'>
         32
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=33 title='Batch Queuing System'>
         33
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=34 title='XSEDE'>
         34
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=35 title='XSEDE Resources'>
         35
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=36 title='XSEDE Resources'>
         36
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=37 title='How do I get started on XSEDE?'>
         37
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=38 title='National Science Foundation (NSF)'>
         38
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=39 title='Department of Energy (DOE)'>
         39
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=40 title='National Center for Atmospheric Research (NCAR)'>
         40
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=41 title='NCAR - CISL (contd)'>
         41
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=42 title='NCAR - CSL'>
         42
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=43 title='HPC Seminars'>
         43
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=44 title='Workshops'>
         44
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=45 title='Upcoming HPC Seminars'>
         45
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=46 title='Getting Help'>
         46
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  
  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>